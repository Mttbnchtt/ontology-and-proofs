{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "print(\"---\")\n",
    "\n",
    "# install and import modules\n",
    "%pip install rdflib\n",
    "\n",
    "import google\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import os\n",
    "import tabulate\n",
    "import typing\n",
    "\n",
    "# mount drive here to read files from the folder \"My Drive > Colab_Notebooks > Formal_Ontology_of_Mathematics > creativity\"\n",
    "google.colab.drive.mount('/content/drive')\n",
    "\n",
    "os.chdir(\"/content/drive/My Drive/Colab_Notebooks/Formal_Ontology_of_Mathematics/creativity\")\n",
    "\n",
    "print(\"---\")\n",
    "!pwd\n",
    "\n",
    "print(\"---\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8zj8IMwnqvK"
   },
   "source": [
    "# ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "file_name = \"ontology_output_v2.ttl\"\n",
    "\n",
    "\n",
    "direct_history_preface = {\n",
    "    \"direct_history_definitions.sparql\",\n",
    "    \"direct_history_postulates.sparql\",\n",
    "    \"direct_history_common_notions.sparql\"\n",
    "}\n",
    "\n",
    "hierarhical_history_preface = {\n",
    "    \"hierarchical_history_definitions.sparql\",\n",
    "    \"hierarchical_history_postulates.sparql\",\n",
    "    \"hierarchical_history_common_notions.sparql\"\n",
    "}\n",
    "\n",
    "indirect_mereological_history_medium_importance_preface = {\n",
    "    \"horizontal_history_part1_definitions.sparql\",\n",
    "    \"horizontal_history_part1_postulates.sparql\",\n",
    "    \"horizontal_history_part1_common_notions.sparql\"\n",
    "}\n",
    "\n",
    "hebbian_connections_preface = {\n",
    "    \"hebbian_connections_definitions.sparql\",\n",
    "    \"hebbian_connections_postulates.sparql\",\n",
    "    \"hebbian_connections_common_notions.sparql\"\n",
    "}\n",
    "\n",
    "def direct_sparql_template_propositions_proofs(iris: str):\n",
    "    return f\"\"\"\n",
    "        SELECT ?o (count (*) as ?links) WHERE {{\n",
    "        values ?s {{ {iris} }}\n",
    "            {{ ?s <https://www.foom.com/core#refers_to> ?o . }} # refers to\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#contains_concept> ?o . }} # refers to / contains concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to> ?o . }} # refers to\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range> ?o . }} # refers to / range\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o . }} # refers to / range / contains concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain> ?o . }} # refers to / domain\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o . }} # refers to / domain / contains concept\n",
    "        }} group by ?o order by desc(?links)\n",
    "    \"\"\"\n",
    "\n",
    "def hierarchical_sparql_template_propositions_proofs(iris: str):\n",
    "    return f\"\"\"\n",
    "        SELECT ?o (count (*) as ?links) WHERE {{\n",
    "        values ?s {{ {iris} }}\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#is_sub_concept_of> ?o . }} # refers to / contains concept / super-concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#is_sub_concept_of>  ?o . }} # refers to / range / contains concept / super-concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#is_sub_concept_of>  ?o . }} # refers to / domain / contains concept / super-concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#refers_to> ?o . }} # refers to [2]\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#contains_concept> ?o . }} # refers to [2] / contains concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range> ?o . }} # refers to [2] / range\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o . }} # refers to [2] / range / contains concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain> ?o . }} # refers to [2] / domain\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o . }} # refers to [2] / domain / contains concept\n",
    "        }} group by ?o order by desc(?links)\n",
    "    \"\"\"\n",
    "\n",
    "def mereological_sparql_template_propositions_proofs(iris: str):\n",
    "    return f\"\"\"\n",
    "        SELECT ?o (count (*) as ?links) WHERE {{\n",
    "        values ?s {{ {iris} }}\n",
    "        {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#contains_concept> ?o . }} # refers to / contains concept / contains concept\n",
    "            UNION\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#definition_refers_to> ?o . }} # refers to / contains concept / contains concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o . }} # refers to / range / contains concept / super-concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#definition_refers_to>  ?o . }} # refers to / range / contains concept / super-concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o . }} # refers to / domain / contains concept / super-concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain>\n",
    "                    / <https://www.foom.com/core#contains_concept>\n",
    "                    / <https://www.foom.com/core#definition_refers_to>  ?o . }} # refers to / range / contains concept / super-concept\n",
    "        }} group by ?o order by desc(?links)\n",
    "    \"\"\"\n",
    "\n",
    "def hebbian_sparql_template_propositions_proofs(iris: str):\n",
    "    return f\"\"\"\n",
    "        SELECT ?o1 ?o2 (COUNT(*) AS ?links)\n",
    "        values ?s {{ {iris} }}\n",
    "            {{ ?s <https://www.foom.com/core#refers_to> ?o1 , ?o2 . }} # refers to\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#contains_concept> ?o1 , ?o2 . }} # refers to / contains concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range> ?o1 , ?o2 . }} # refers to / range\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_range>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o1 , ?o2 . }} # refers to / range / contains concept\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain> ?o1 , ?o2 . }} # refers to / domain\n",
    "            union\n",
    "            {{ ?s <https://www.foom.com/core#refers_to>\n",
    "                    / <https://www.foom.com/core#has_domain>\n",
    "                    / <https://www.foom.com/core#contains_concept>  ?o1 , ?o2 . }} # refers to / domain / contains concept\n",
    "            FILTER ( STR(?o1) < STR(?o2) )\n",
    "        }} GROUP BY ?o1 ?o2 ORDER BY DESC(?links)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions\n",
    "\n",
    "def access_graph(file_name: str,\n",
    "                 folder_name: str = \"input\") -> rdflib.Graph:\n",
    "    \"\"\"Accesses the RDF graph from the specified file.\n",
    "\n",
    "    Args:\n",
    "        file_name: The name of the file containing the RDF graph (e.g., \"ontology_output.ttl\").\n",
    "\n",
    "    Returns:\n",
    "        An rdflib.Graph object representing the RDF graph.\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(folder_name, file_name)\n",
    "    return rdflib.Graph().parse(input_file)\n",
    "\n",
    "\n",
    "def run_sparql_query(knowledge_graph: rdflib.Graph,\n",
    "                     sparql_query_name: str,\n",
    "                     folder_name: str = os.path.join(\"input\", \"sparql_queries\")\n",
    "                     ) -> rdflib.query.Result:\n",
    "    \"\"\"Runs a SPARQL query on the provided knowledge graph.\n",
    "\n",
    "    Args:\n",
    "        knowledge_graph: The rdflib.Graph object representing the knowledge graph.\n",
    "        sparql_query_name: The name of the SPARQL query file (e.g., \"query_6.sparql\").\n",
    "        folder_name: The folder containing the SPARQL query file. Defaults to \"input/sparql_queries\".\n",
    "\n",
    "    Returns:\n",
    "        The result of the SPARQL query as an rdflib.query.Result object.\n",
    "    \"\"\"\n",
    "    # create path to sparql query\n",
    "    query_path = os.path.join(folder_name, sparql_query_name)\n",
    "\n",
    "    # access the sparql query and run it on the knowledge graph\n",
    "    with open(query_path, \"r\") as query_file:\n",
    "        sparql_query = query_file.read()\n",
    "    return knowledge_graph.query(sparql_query)\n",
    "\n",
    "\n",
    "def get_table_history_queries(knowledge_graph: rdflib.Graph,\n",
    "                              sparql_queries: set = direct_history_preface\n",
    "                              ) -> pd.DataFrame:\n",
    "    all_results = []\n",
    "    # Run SPARQL queries and append results to the list\n",
    "    for sparql_query in sparql_queries:\n",
    "        sparql_results = run_sparql_query(knowledge_graph, sparql_query)\n",
    "        for result in sparql_results:\n",
    "            all_results.append([\n",
    "                getattr(result.o, \"toPython\", lambda: result.o)(),  # Use getattr with default lambda\n",
    "                int(result.links)\n",
    "            ])\n",
    "    # Return the pandas DataFrame from the list of results\n",
    "    results = pd.DataFrame(all_results,\n",
    "                        columns=[\"conceptual_item\", \"use_number\"])\n",
    "    return results\n",
    "\n",
    "def get_table_hebbian_queries(knowledge_graph: rdflib.Graph,\n",
    "                              sparql_queries: set = direct_history_preface\n",
    "                              ) -> pd.DataFrame:\n",
    "    all_results = []\n",
    "    # Run SPARQL queries and append results to the list\n",
    "    for sparql_query in sparql_queries:\n",
    "        sparql_results = run_sparql_query(knowledge_graph, sparql_query)\n",
    "        for result in sparql_results:\n",
    "            all_results.append([\n",
    "                getattr(result.o1, \"toPython\", lambda: result.o1)(),  # Use getattr with default lambda\n",
    "                getattr(result.o2, \"toPython\", lambda: result.o2)(),  # Use getattr with default lambda\n",
    "                int(result.links)\n",
    "            ])\n",
    "    # Return the pandas DataFrame from the list of results\n",
    "    results = pd.DataFrame(all_results,\n",
    "                        columns=[\"conceptual_item_1\", \"conceptual_item_2\", \"use_number\"])\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_table_with_links(knowledge_graph: rdflib.Graph,\n",
    "                         sparql_queries: set = direct_history_preface,\n",
    "                         history_table_option: bool = True\n",
    "                         ) -> pd.DataFrame:\n",
    "    \"\"\"Retrieves a table of textual units, conceptual items, and their usage numbers.\n",
    "\n",
    "    Executes a set of SPARQL queries on the knowledge graph to extract links between\n",
    "    textual units and conceptual items, along with their usage numbers.\n",
    "\n",
    "    Args:\n",
    "        knowledge_graph: The rdflib.Graph object representing the knowledge graph.\n",
    "        sparql_queries: A list of SPARQL query names to execute. Defaults to sparql_queries_withouth_hierarchical_imports.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with columns \"textual_unit\", \"conceptual_item\", and \"use_number\".\n",
    "    \"\"\"\n",
    "    if history_table_option:\n",
    "        results = get_table_history_queries(knowledge_graph, sparql_queries)\n",
    "    else:\n",
    "        results = get_table_hebbian_queries(knowledge_graph, sparql_queries)\n",
    "\n",
    "    # Order results\n",
    "    results = results.sort_values(by=[\"use_number\"], ascending=[False])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_-dS-krn_N6"
   },
   "source": [
    "## HISTORICAL ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preface_history(kg: rdflib.Graph,\n",
    "                        direct_history_preface: set = direct_history_preface,\n",
    "                        hierarhical_history_preface: set = hierarhical_history_preface,\n",
    "                        indirect_mereological_history_medium_importance_preface: set = indirect_mereological_history_medium_importance_preface,\n",
    "                        sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\")):\n",
    "    # preface history: definition, postulates, common axioms\n",
    "    direct_history_preface_df = get_table_with_links(kg, direct_history_preface)\n",
    "\n",
    "    # get indirect hierarchical history\n",
    "    hierachical_history_preface_df = get_table_with_links(kg, hierarhical_history_preface)\n",
    "\n",
    "    # get indirect mereological history\n",
    "    indirect_mereological_history_preface_df = get_table_with_links(kg, indirect_mereological_history_medium_importance_preface)\n",
    "\n",
    "    return [direct_history_preface_df, hierachical_history_preface_df, indirect_mereological_history_preface_df]\n",
    "\n",
    "def historical_activation_computation(historical_activation_potential: dict,\n",
    "                                      specific_history: pd.DataFrame,\n",
    "                                      weight: float):\n",
    "    total = specific_history[\"use_number\"].sum()\n",
    "    for index in specific_history.index:\n",
    "        conceptual_item = specific_history[\"conceptual_item\"][index]\n",
    "        historical_activation_potential[conceptual_item] += ( (weight * specific_history[\"use_number\"][index]) / total )\n",
    "    return historical_activation_potential\n",
    "\n",
    "def get_historical_activation_potential(history: list,\n",
    "                                        weights: list = [6/9, 1/9, 2/9]):\n",
    "    # initialize the dictionary to compute the historical activation potential\n",
    "    historical_activation_potential = {\n",
    "        conceptual_item: 0\n",
    "            for specific_history in history\n",
    "            for conceptual_item in specific_history[\"conceptual_item\"]\n",
    "    }\n",
    "    # add the use numbers from the three histories\n",
    "    for specific_history, weight in zip(history, weights):\n",
    "        activation = historical_activation_computation(\n",
    "            historical_activation_potential, specific_history, weight)\n",
    "\n",
    "    # convert the dictionary to a dataframe\n",
    "    historical_activation_potential = pd.DataFrame(\n",
    "            list(historical_activation_potential.items()),\n",
    "            columns=['conceptual_item', 'activation_potential']\n",
    "        )\n",
    "\n",
    "    return historical_activation_potential\n",
    "\n",
    "def get_history_proposition(kg,\n",
    "                            proposition_number: int = 1):\n",
    "    proposition_iri = f\"https://www.foom.com/core#proposition_{proposition_number}\"\n",
    "    # direct history\n",
    "    direct_history_proposition_query = direct_sparql_template_propositions_proofs(proposition_iri)\n",
    "    direct_history_proposition_df = get_table_with_links(kg, {direct_history_proposition_query})\n",
    "    # hierarchical history\n",
    "    hierarchical_history_proposition_query = hierarchical_sparql_template_propositions_proofs(proposition_iri)\n",
    "    hierarchical_history_proposition_df = get_table_with_links(kg, {hierarchical_history_proposition_query})\n",
    "    # mereological history\n",
    "    mereological_history_proposition_query = mereological_sparql_template_propositions_proofs(proposition_iri)\n",
    "    mereological_history_proposition_df = get_table_with_links(kg, {mereological_history_proposition_query})\n",
    "    return [direct_history_proposition_df, hierarchical_history_proposition_df, mereological_history_proposition_df]\n",
    "\n",
    "def combine_old_and_new_history(old_history: list, new_history: list):\n",
    "    histories = []\n",
    "    for old_history_df, new_history_df in zip(old_history, new_history):\n",
    "        # make weighted copy of new_history_df\n",
    "        new_history_double_values_df = new_history_df.copy()\n",
    "        new_history_double_values_df[\"use_number\"] = new_history_df[\"use_number\"] * 2\n",
    "        # concat old and new histories\n",
    "        history_df = pd.concat([old_history_df, new_history_double_values_df], ignore_index=True)\n",
    "        # group by conceptual_item and sum use_number\n",
    "        history_df = history_df.groupby(\"conceptual_item\", as_index=False)[\"use_number\"].sum()\n",
    "        histories.append(history_df)\n",
    "    return histories\n",
    "\n",
    "def get_history(kg: rdflib.Graph,\n",
    "                sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\"),\n",
    "                up_to_proposition: int = 0,\n",
    "                base: dict = {}):\n",
    "    if base:\n",
    "        pass\n",
    "        # find highest proposition P in base\n",
    "        # if P < up_to_proposition,\n",
    "        # find the history of the propositions\n",
    "        # between P (excluded) and up_to_proposition (included)\n",
    "\n",
    "        # if P = up_to_proposition,\n",
    "        # find the history of the propositions\n",
    "        # between P (excluded) and up_to_proposition (included)\n",
    "\n",
    "        # if P > up_to_proposition,\n",
    "        # remove the history for propositions > up_to_proposition\n",
    "        # return history\n",
    "    else:\n",
    "        # get direct history of definitions, postulates, and common notions\n",
    "\n",
    "        # get direct history up to the given proposition number\n",
    "        if up_to_proposition == 0:\n",
    "            history = get_preface_history(kg)\n",
    "            return history\n",
    "        elif up_to_proposition == 1:\n",
    "            # get previous history\n",
    "            previous_history = get_preface_history(kg)\n",
    "            # get history of proposition 1\n",
    "            new_history = get_history_proposition\n",
    "            # combine histories\n",
    "            return combine_old_and_new_history(previous_history, new_history)\n",
    "        elif up_to_proposition > 1:\n",
    "            pass\n",
    "            # return history\n",
    "        else:\n",
    "            return ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEEHJWc6d2J_"
   },
   "source": [
    "## HEBBIAN ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_hebbian_table(kg: rdflib.Graph,\n",
    "#                       sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\"),\n",
    "#                       up_to_proposition: int = 0):\n",
    "#     # get_hebbian_connections\n",
    "#     hebbian_connections = get_table_with_links(kg, hebbian_connections_preface, history_table_option = False)\n",
    "\n",
    "#     return hebbian_connections\n",
    "\n",
    "\n",
    "def compute_hebbian_activation(hebbian_table: pd.DataFrame):\n",
    "    # initialize dictionary for hebbian activation potentials\n",
    "    hebbian_potential = {}\n",
    "    # sum of all hebbian connections\n",
    "    total_use_number = hebbian_table['use_number'].sum()\n",
    "    # add hebbian activation potentials to the dictionary\n",
    "    for row in hebbian_table.itertuples():\n",
    "        concepts = tuple(sorted([row.conceptual_item_1, row.conceptual_item_2]))\n",
    "        hebbian_activation = row.use_number / total_use_number\n",
    "        hebbian_potential[concepts] = hebbian_activation\n",
    "\n",
    "    hebbian_df = pd.DataFrame(list(hebbian_potential.items()),\n",
    "                              columns=[\"conceptual_item\", \"activation_potential\"])\n",
    "\n",
    "    return hebbian_df\n",
    "\n",
    "def get_hebbian_activation(kg: rdflib.Graph,\n",
    "                           sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\"),\n",
    "                           sparql_queries: set = hebbian_connections_preface,\n",
    "                           up_to_proposition: int = 0,\n",
    "                           base: dict = {}):\n",
    "    if base:\n",
    "        pass\n",
    "    else:\n",
    "        if up_to_proposition == 0:\n",
    "            hebbian_table = get_table_with_links(kg, sparql_queries, history_table_option = False)\n",
    "            hebbian_potential = compute_hebbian_activation(hebbian_table)\n",
    "            return hebbian_potential\n",
    "        elif up_to_proposition > 1:\n",
    "            pass\n",
    "        else:\n",
    "            return ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S50yRm-iGqb9"
   },
   "source": [
    "# UNIFIED ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(historical_activation_potential: pd.DataFrame,\n",
    "                hebbian_activation_potential: pd.DataFrame):\n",
    "    context = set(historical_activation_potential['conceptual_item'])\n",
    "    for pair in hebbian_activation_potential['conceptual_item']:\n",
    "        context.update(pair)\n",
    "    return context\n",
    "\n",
    "def calculate_activation(conceptual_item,\n",
    "                         historical_activation_potential_dict: dict,\n",
    "                         hebbian_activation_potential_dict: dict,\n",
    "                         history_weight: float = 2/3,\n",
    "                         hebbian_weight: float = 1/3):\n",
    "    # history part\n",
    "    weigthed_historical_activation = history_weight * historical_activation_potential_dict.get(conceptual_item, 0)\n",
    "    # hebbian part\n",
    "    weighted_hebbian_activation = 0\n",
    "    for items_pair, value in hebbian_activation_potential_dict.items():\n",
    "        if conceptual_item in items_pair:\n",
    "            weighted_hebbian_activation += hebbian_weight * hebbian_activation_potential_dict[items_pair] / 2\n",
    "    # total activation potential\n",
    "    return weigthed_historical_activation + weighted_hebbian_activation\n",
    "\n",
    "def get_activation_potential(historical_activation_potential: pd.DataFrame,\n",
    "                             hebbian_activation_potential: pd.DataFrame):\n",
    "    # get context\n",
    "    context = get_context(historical_activation_potential, hebbian_activation_potential)\n",
    "    # create dictionaries\n",
    "    historical_activation_potential_dict = dict(zip(historical_activation_potential['conceptual_item'],\n",
    "                                                    historical_activation_potential['activation_potential']))\n",
    "    hebbian_activation_potential_dict = dict(zip(hebbian_activation_potential['conceptual_item'],\n",
    "                                                 hebbian_activation_potential['activation_potential']))\n",
    "\n",
    "    # initialize dictionary of unified activation potentials\n",
    "    activations = {}\n",
    "\n",
    "    # calculate the unified activation potential for each conceptual item\n",
    "    for conceptual_item in context:\n",
    "        activations[conceptual_item] = calculate_activation(\n",
    "                conceptual_item,\n",
    "                historical_activation_potential_dict,\n",
    "                hebbian_activation_potential_dict\n",
    "            )\n",
    "    activations_df = pd.DataFrame(list(activations.items()),\n",
    "                                  columns=[\"conceptual_item\", \"activation_potential\"])\n",
    "    return activations_df.sort_values(by=[\"activation_potential\"], ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO5LCVlWeA4d"
   },
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_name: str,\n",
    "         display_tables: bool = True):\n",
    "    # access turtle file\n",
    "    kg = access_graph(file_name)\n",
    "\n",
    "    ###########\n",
    "    # preface\n",
    "        # history\n",
    "    history = get_history(kg)\n",
    "    historical_activation_potential = get_historical_activation_potential(history)\n",
    "    if display_tables:\n",
    "        print(f\"Sum historical activation potential: {historical_activation_potential['activation_potential'].sum()}\")\n",
    "        IPython.display.display(IPython.display.HTML(historical_activation_potential.to_html()))\n",
    "\n",
    "        # hebbian\n",
    "    hebbian_activation_potential = get_hebbian_activation(kg)\n",
    "    if display_tables:\n",
    "        print(f\"Sum hebbian activation potential: {hebbian_activation_potential['activation_potential'].sum()}\")\n",
    "        IPython.display.display(IPython.display.HTML(hebbian_activation_potential.to_html()))\n",
    "\n",
    "        # activation potential\n",
    "    activation_potential_df = get_activation_potential(\n",
    "            historical_activation_potential,\n",
    "            hebbian_activation_potential\n",
    "        )\n",
    "    if display_tables:\n",
    "        print(f\"Sum total activation potential: {activation_potential_df['activation_potential'].sum()}\")\n",
    "        IPython.display.display(IPython.display.HTML(activation_potential_df.to_html()))\n",
    "\n",
    "    return activation_potential\n",
    "\n",
    "\n",
    "activation_potential_df = main(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_potential_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_potential_df.to_csv(\"output/activation_potential.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
