# -*- coding: utf-8 -*-
"""creativity_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dvqyRlsa5Z6O8ZmLDsfO3CAoTJUCm4Hg
"""

# Commented out IPython magic to ensure Python compatibility.
!python --version
print("---")

# install and import modules
# %pip install rdflib

import google
import IPython
import json
import pandas as pd
import rdflib
import os
import tabulate
import typing

# mount drive here to read files from the folder "My Drive > Colab_Notebooks > Formal_Ontology_of_Mathematics > creativity"
google.colab.drive.mount('/content/drive')

os.chdir("/content/drive/My Drive/Colab_Notebooks/Formal_Ontology_of_Mathematics/creativity")

print("---")
!pwd

print("---")
!ls

import modules.queries as queries

# parameters
file_name = "ontology_output_v3.ttl"

# general functions
def access_graph(file_name: str,
                 folder_name: str = "input") -> rdflib.Graph:
    input_file = os.path.join(folder_name, file_name)
    return rdflib.Graph().parse(input_file)

def sparql_to_df(kg: rdflib.Graph,
                 sparql_query: str):
    raw = kg.query(sparql_query)
    variables = raw.vars
    records = [{str(variables[i]): str(item) for i, item in enumerate(row)} for row in raw]
    records_df = pd.DataFrame(records)
    if "links" in records_df.columns:
        records_df["links"] = records_df["links"].astype(int)
    return records_df

def sparql_to_concat_df(kg: rdflib.Graph,
                        sparql_queries: list,
                        hebb: bool = False):
    if hebb:
        df = pd.concat(
            [sparql_to_df(kg, sparql_query) for sparql_query in sparql_queries ],
            ignore_index = True).groupby(by=["o1", "o2"])["links"].sum().reset_index()
    else:
        df = pd.concat(
            [sparql_to_df(kg, sparql_query) for sparql_query in sparql_queries ],
            ignore_index = True).groupby(by=["o"])["links"].sum().reset_index()
    return df

def history(kg: rdflib.Graph,
                    sparql_queries: list = [
                        [queries.direct_definitions(), queries.direct_postulates(), queries.direct_common_notions()],
                        [queries.hierarchical_definitions(), queries.hierarchical_postulates(), queries.hierarchical_common_notions()],
                        [queries.mereological_definitions(), queries.mereological_postulates(), queries.mereological_common_notions()] ],
                    weights: list = [6/9, 1/9, 2/9]):
    histories = [sparql_to_concat_df(kg, sparql_queries[0]), sparql_to_concat_df(kg, sparql_queries[1]), sparql_to_concat_df(kg, sparql_queries[2])]
    activation_dfs = []
    # calculation of activation potentials
    for history_df, weight in zip(histories, weights):
        total_use = history_df["links"].sum()
        actions_df = history_df.assign(
            activation_potential = (history_df["links"] * weight) / total_use
        )[["o", "activation_potential"]]
        activation_dfs.append(actions_df)

    # combine dataframes
    combined_df = pd.concat(activation_dfs, ignore_index=True)
    return combined_df.groupby("o")["activation_potential"].sum().reset_index()

def hebb(kg: rdflib.Graph,
                 sparql_queries: list = [queries.hebb_definitions(), queries.hebb_postulates(), queries.hebb_common_notions()]):
    df = sparql_to_concat_df(kg, sparql_queries, hebb=True)
    total_use = df["links"].sum()
    df["activation_potential"] = df["links"] / total_use
    df = df.drop(columns=["links"])
    df = df.sort_values(by="activation_potential", ascending=False)
    df = df.reset_index(drop=True)
    return df

# def calculate_preface_potentials(kg: rdflib.Graph):
def calculate_activation_potential(kg: rdflib.Graph,
                                   proposition_number: int = 0):
    # history potential
    history_potential = history(kg)
    print(len(history_potential))
    print(history_potential[:20])
    print(history_potential["activation_potential"].sum())

    # hebb potential
    hebb_potential = hebb(kg)
    print(len(hebb_potential))
    print(hebb_potential[:20])
    print(hebb_potential["activation_potential"].sum())

    return [], []

def main(file_name: str = file_name,
         proposition_number: int = 1):
    # access turtle file and put content in the kg (rdflib.Graph)
    kg = access_graph(file_name)
    #  calculate activation potential
    preface_history, preface_cooccurrence = calculate_activation_potential(kg)


    # check surprise score

    return

main()



