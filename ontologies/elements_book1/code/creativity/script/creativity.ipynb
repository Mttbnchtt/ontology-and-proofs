{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "print(\"---\")\n",
    "\n",
    "# install and import modules\n",
    "%pip install rdflib\n",
    "\n",
    "import google\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import os\n",
    "import typing\n",
    "\n",
    "# mount drive here to read files from the folder \"My Drive > Colab_Notebooks > Formal_Ontology_of_Mathematics > creativity\"\n",
    "google.colab.drive.mount('/content/drive')\n",
    "\n",
    "os.chdir(\"/content/drive/My Drive/Colab_Notebooks/Formal_Ontology_of_Mathematics/creativity\")\n",
    "\n",
    "print(\"---\")\n",
    "!pwd\n",
    "\n",
    "print(\"---\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "file_name = \"ontology_output.ttl\"\n",
    "sparql_queries_withouth_hierarchical_imports: list = [\n",
    "    \"query_6.sparql\",\n",
    "    \"query_7.sparql\",\n",
    "    \"query_8.sparql\",\n",
    "    \"query_12.sparql\",\n",
    "    \"query_14.sparql\"\n",
    "]\n",
    "\n",
    "sparql_queries_with_hierarchical_imports: list = [\n",
    "    \"query_9.sparql\",\n",
    "    \"query_10.sparql\",\n",
    "    \"query_11.sparql\",\n",
    "    \"query_13.sparql\",\n",
    "    \"query_15.sparql\"\n",
    "]\n",
    "\n",
    "def access_graph(file_name: str):\n",
    "    input_file = os.path.join(\"input\", file_name)\n",
    "    return rdflib.Graph().parse(input_file)\n",
    "\n",
    "def run_sparql_query(knowledge_graph: rdflib.Graph,\n",
    "                     sparql_query_name: str,\n",
    "                     folder_name: str = os.path.join(\"input\", \"sparql_queries\")\n",
    "                     ):\n",
    "    # create path to sparql query\n",
    "    query_path = os.path.join(folder_name, sparql_query_name)\n",
    "\n",
    "    # access the sparql query and run it on the knowledge graph\n",
    "    with open(query_path, \"r\") as query_file:\n",
    "        sparql_query = query_file.read()\n",
    "    return knowledge_graph.query(sparql_query)\n",
    "\n",
    "def get_table_with_links(knowledge_graph: rdflib.Graph,\n",
    "                         sparql_queries: set = sparql_queries_withouth_hierarchical_imports):\n",
    "    # Initialize an empty list to store results\n",
    "    all_results = []\n",
    "\n",
    "    # Run SPARQL queries and append results to the list\n",
    "    for sparql_query in sparql_queries:\n",
    "        sparql_results = run_sparql_query(knowledge_graph, sparql_query)\n",
    "        for result in sparql_results:\n",
    "            all_results.append([\n",
    "                result.s.toPython() if hasattr(result.s, \"toPython\") else result.s,\n",
    "                result.o.toPython() if hasattr(result.o, \"toPython\") else result.o,\n",
    "                int(result.links)])\n",
    "\n",
    "    # Create the pandas DataFrame from the list of results\n",
    "    links = pd.DataFrame(all_results,\n",
    "                         columns=[\"textual_unit\", \"conceptual_item\", \"use_number\"])\n",
    "\n",
    "    return links  # Return the DataFrame\n",
    "\n",
    "def dataframe_to_csv(df: pd.DataFrame,\n",
    "                     filename: str = \"output.csv\",\n",
    "                     output_folder: str = \"output\"):\n",
    "    \"\"\"Saves a pandas DataFrame to a CSV file in the 'output' folder.\n",
    "\n",
    "    Args:\n",
    "        df: The pandas DataFrame to save.\n",
    "        filename: The name of the CSV file (default: \"output.csv\").\n",
    "    \"\"\"\n",
    "    # Construct the full file path\n",
    "    filepath = os.path.join(output_folder, f\"{filename}.csv\")\n",
    "\n",
    "    # Save the DataFrame to the CSV file\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"DataFrame saved to: {filepath}\")\n",
    "\n",
    "def get_tables_of_textual_units_and_concepts(file_name: str):\n",
    "    # access turtle file\n",
    "    # and populate a Graph object\n",
    "    kg = access_graph(file_name)\n",
    "\n",
    "    # table of textual units and direct concepts\n",
    "    direct_links = get_table_with_links(kg,\n",
    "                                        sparql_queries_withouth_hierarchical_imports)\n",
    "\n",
    "    # table of textual units and indirect concepts\n",
    "    indirect_links = get_table_with_links(kg,\n",
    "                                          sparql_queries_with_hierarchical_imports)\n",
    "\n",
    "    return direct_links, indirect_links\n",
    "\n",
    "def main_get_tables_of_textual_units_and_concepts(file_name: str):\n",
    "    direct_links, indirect_links = get_tables_of_textual_units_and_concepts(file_name)\n",
    "\n",
    "    dataframe_to_csv(direct_links, \"direct_links\")\n",
    "    dataframe_to_csv(indirect_links, \"indirect_links\")\n",
    "\n",
    "    return direct_links, indirect_links\n",
    "\n",
    "direct_links, indirect_links = main_get_tables_of_textual_units_and_concepts(file_name)\n",
    "direct_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "file_name = \"ontology_output.ttl\"\n",
    "\n",
    "def access_graph(file_name: str):\n",
    "    input_file = os.path.join(\"input\", file_name)\n",
    "    return rdflib.Graph().parse(input_file)\n",
    "\n",
    "def run_sparql_query(knowledge_graph: rdflib.Graph,\n",
    "                     sparql_query_name: str,\n",
    "                     folder_name: str = os.path.join(\"input\", \"sparql_queries\")\n",
    "                     ):\n",
    "    # create path to sparql query\n",
    "    query_path = os.path.join(folder_name, sparql_queries[sparql_query_name])\n",
    "    # access the sparql query and run it on the knowledge graph\n",
    "    with open(query_path, \"r\") as query_file:\n",
    "        sparql_query = query_file.read()\n",
    "    return knowledge_graph.query(sparql_query)\n",
    "\n",
    "def get_initial_activation_potential(knowledge_graph: rdflib.Graph,\n",
    "                                     sparql_queries_direct_link: set = {\n",
    "                                         \"query_6.sparql\",\n",
    "                                         \"query_7.sparql\",\n",
    "                                         \"query_8.sparql\n",
    "                                     },\n",
    "                                     sparql_queries_hierachical_link: set = {\n",
    "                                         \"query_9.sparql\",\n",
    "                                         \"query_10.sparql\",\n",
    "                                         \"query_11.sparql\n",
    "                                     }\n",
    "                                     ):\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def prepare_initial_hebbian_connections():\n",
    "    return\n",
    "\n",
    "\n",
    "def main_routine_starting_state(file_name: str):\n",
    "    # access turtle file\n",
    "    # and populate a Graph object\n",
    "    kg = access_graph(file_name)\n",
    "\n",
    "    # run sparql queries;\n",
    "    # organize the query results;\n",
    "    # return several analytical results,\n",
    "    # including the initial state concerning the activation potential\n",
    "    # of the conceptual items in the graph\n",
    "\n",
    "    # initial_state_intermediate_results, initial_state = get_initial_state_euclid(kg)\n",
    "\n",
    "    return initial_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"creativity_graph.nt\"\n",
    "file_name = \"ontology_output.ttl\"\n",
    "sparql_queries: dict = {\n",
    "    \"definitions\": \"query_3.sparql\",\n",
    "    \"postulates\": \"query_1.sparql\",\n",
    "    \"common_notions\": \"query_2.sparql\",\n",
    "    \"propositions\": \"query_4.sparql\",\n",
    "    \"proofs\": \"query_5.sparql\",\n",
    "}\n",
    "\n",
    "\n",
    "def access_graph(file_name: str):\n",
    "    input_file = os.path.join(\"input\", file_name)\n",
    "    return rdflib.Graph().parse(input_file)\n",
    "\n",
    "def run_sparql_query(knowledge_graph: rdflib.Graph,\n",
    "                     sparql_query_name: str,\n",
    "                     folder_name: str = \"input\"):\n",
    "    # create path to sparql query\n",
    "    query_path = os.path.join(folder_name, sparql_queries[sparql_query_name])\n",
    "    # access the sparql query and run it on the knowledge graph\n",
    "    with open(query_path, \"r\") as query_file:\n",
    "        sparql_query = query_file.read()\n",
    "    return knowledge_graph.query(sparql_query)\n",
    "\n",
    "def get_connection_weights(knowledge_graph: rdflib.Graph,\n",
    "                           sparql_queries_initial_state: set = {\"definitions\", \"postulates\", \"common_notions\"}):\n",
    "    # initialize dictionary to store the query results\n",
    "    results: dict = {\n",
    "        \"subject\": [],\n",
    "        \"object\": [],\n",
    "        \"connection_weight\": []\n",
    "        }\n",
    "    for sparql_query_name in sparql_queries_initial_state:\n",
    "        query_results = run_sparql_query(knowledge_graph, sparql_query_name)\n",
    "        for result in query_results:\n",
    "            results[\"subject\"].append(result.s)\n",
    "            results[\"object\"].append(result.o)\n",
    "            results[\"connection_weight\"].append(int(result.links))\n",
    "\n",
    "    return results\n",
    "\n",
    "def join_results(list_of_results: list):\n",
    "    joined_results: dict = {}\n",
    "\n",
    "    for result in list_of_results:\n",
    "        for subject_triple, object_triple, connection_weight in zip(result[\"subject\"], result[\"object\"], result[\"connection_weight\"]):\n",
    "            key: str = f\"{subject_triple}||{object_triple}\"\n",
    "            joined_results[key] = joined_results.get(key, 0) + connection_weight\n",
    "    return joined_results\n",
    "\n",
    "def prepare_intermediate_results_dataframe(joined_results: dict):\n",
    "    # initial_state = pd.DataFrame(columns=[\"subject\", \"object\", \"connection_weight\"])\n",
    "    initial_state_intermediate_results: dict = {\n",
    "        \"subject\": [],\n",
    "        \"object\": [],\n",
    "        \"use_iterations\": []\n",
    "    }\n",
    "    for key, value in joined_results.items():\n",
    "        subject_triple, object_triple = key.split(\"||\")\n",
    "        initial_state_intermediate_results[\"subject\"].append(subject_triple)\n",
    "        initial_state_intermediate_results[\"object\"].append(object_triple)\n",
    "        initial_state_intermediate_results[\"use_iterations\"].append(value)\n",
    "    return pd.DataFrame(initial_state_intermediate_results)\n",
    "\n",
    "def prepare_initial_state_dataframe(initial_state_intermediate_result: pd.DataFrame):\n",
    "    # Group by the 'object' column, summing up the connection_weight\n",
    "    intial_state: pd.DataFrame = initial_state_intermediate_result.groupby('object', as_index=False)['use_iterations'].sum()\n",
    "\n",
    "    # Rename columns\n",
    "    intial_state.columns = ['conceptual_item', 'use_weight']\n",
    "\n",
    "    # Sort the DataFrame by 'use_weight' in descending order\n",
    "    intial_state = intial_state.sort_values(by='use_weight', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return intial_state\n",
    "\n",
    "\n",
    "def get_initial_state_euclid(knowledge_graph: rdflib.Graph):\n",
    "    list_of_results = []\n",
    "\n",
    "    # get connection from definitions,\n",
    "    # postulates, and common notions\n",
    "    list_of_results.append(get_connection_weights(knowledge_graph))\n",
    "\n",
    "    # join results\n",
    "    joined_results = join_results(list_of_results)\n",
    "\n",
    "    # prepare dataframe of the initial state\n",
    "    initial_state_intermediate_results_with_hierarhical_imports = prepare_intermediate_results_dataframe(joined_results)\n",
    "    initial_state_with_hierarchical_imports = prepare_initial_state_dataframe(initial_state_intermediate_results_with_hierarhical_imports)\n",
    "\n",
    "    return initial_state_intermediate_results_with_hierarhical_imports, initial_state_with_hierarchical_imports\n",
    "\n",
    "def main_routine_starting_state(file_name: str):\n",
    "    kg = access_graph(file_name)\n",
    "    initial_state_intermediate_results, initial_state = get_initial_state_euclid(kg)\n",
    "\n",
    "    return initial_state\n",
    "\n",
    "initial_state: pd.DataFrame = main_routine_starting_state(file_name)\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSBDR9ZqrjBc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_initial_state_euclid(access_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
