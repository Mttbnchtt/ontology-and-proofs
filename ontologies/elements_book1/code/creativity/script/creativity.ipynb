{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "print(\"---\")\n",
    "\n",
    "# install and import modules\n",
    "%pip install rdflib\n",
    "\n",
    "import google\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import os\n",
    "import typing\n",
    "\n",
    "# mount drive here to read files from the folder \"My Drive > Colab_Notebooks > Formal_Ontology_of_Mathematics > creativity\"\n",
    "google.colab.drive.mount('/content/drive')\n",
    "\n",
    "os.chdir(\"/content/drive/My Drive/Colab_Notebooks/Formal_Ontology_of_Mathematics/creativity\")\n",
    "\n",
    "print(\"---\")\n",
    "!pwd\n",
    "\n",
    "print(\"---\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8zj8IMwnqvK"
   },
   "source": [
    "# ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "file_name = \"ontology_output_v2.ttl\"\n",
    "\n",
    "\n",
    "direct_history_preface = {\n",
    "    \"direct_history_definitions.sparql\",\n",
    "    \"direct_history_postulates.sparql\",\n",
    "    \"direct_history_common_notions.sparql\"\n",
    "}\n",
    "\n",
    "hierarhical_history_preface = {\n",
    "    \"hierarchical_history_definitions.sparql\",\n",
    "    \"hierarchical_history_postulates.sparql\",\n",
    "    \"hierarchical_history_common_notions.sparql\"\n",
    "}\n",
    "\n",
    "indirect_mereological_history_medium_importance_preface = {\n",
    "    \"horizontal_history_part1_definitions.sparql\",\n",
    "    \"horizontal_history_part1_postulates.sparql\",\n",
    "    \"horizontal_history_part1_common_notions.sparql\"\n",
    "}\n",
    "\n",
    "hebbian_connections_preface = {\n",
    "    \"hebbian_connections_definitions.sparql\",\n",
    "    \"hebbian_connections_postulates.sparql\",\n",
    "    \"hebbian_connections_common_notions.sparql\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions\n",
    "\n",
    "def access_graph(file_name: str,\n",
    "                 folder_name: str = \"input\") -> rdflib.Graph:\n",
    "    \"\"\"Accesses the RDF graph from the specified file.\n",
    "\n",
    "    Args:\n",
    "        file_name: The name of the file containing the RDF graph (e.g., \"ontology_output.ttl\").\n",
    "\n",
    "    Returns:\n",
    "        An rdflib.Graph object representing the RDF graph.\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(folder_name, file_name)\n",
    "    return rdflib.Graph().parse(input_file)\n",
    "\n",
    "\n",
    "def run_sparql_query(knowledge_graph: rdflib.Graph,\n",
    "                     sparql_query_name: str,\n",
    "                     folder_name: str = os.path.join(\"input\", \"sparql_queries\")\n",
    "                     ) -> rdflib.query.Result:\n",
    "    \"\"\"Runs a SPARQL query on the provided knowledge graph.\n",
    "\n",
    "    Args:\n",
    "        knowledge_graph: The rdflib.Graph object representing the knowledge graph.\n",
    "        sparql_query_name: The name of the SPARQL query file (e.g., \"query_6.sparql\").\n",
    "        folder_name: The folder containing the SPARQL query file. Defaults to \"input/sparql_queries\".\n",
    "\n",
    "    Returns:\n",
    "        The result of the SPARQL query as an rdflib.query.Result object.\n",
    "    \"\"\"\n",
    "    # create path to sparql query\n",
    "    query_path = os.path.join(folder_name, sparql_query_name)\n",
    "\n",
    "    # access the sparql query and run it on the knowledge graph\n",
    "    with open(query_path, \"r\") as query_file:\n",
    "        sparql_query = query_file.read()\n",
    "    return knowledge_graph.query(sparql_query)\n",
    "\n",
    "\n",
    "def get_table_history_queries(knowledge_graph: rdflib.Graph,\n",
    "                              sparql_queries: set = direct_history_preface\n",
    "                              ) -> pd.DataFrame:\n",
    "    all_results = []\n",
    "    # Run SPARQL queries and append results to the list\n",
    "    for sparql_query in sparql_queries:\n",
    "        sparql_results = run_sparql_query(knowledge_graph, sparql_query)\n",
    "        for result in sparql_results:\n",
    "            all_results.append([\n",
    "                getattr(result.o, \"toPython\", lambda: result.o)(),  # Use getattr with default lambda\n",
    "                int(result.links)\n",
    "            ])\n",
    "    # Return the pandas DataFrame from the list of results\n",
    "    results = pd.DataFrame(all_results,\n",
    "                        columns=[\"conceptual_item\", \"use_number\"])\n",
    "    return results\n",
    "\n",
    "def get_table_hebbian_queries(knowledge_graph: rdflib.Graph,\n",
    "                              sparql_queries: set = direct_history_preface\n",
    "                              ) -> pd.DataFrame:\n",
    "    all_results = []\n",
    "    # Run SPARQL queries and append results to the list\n",
    "    for sparql_query in sparql_queries:\n",
    "        sparql_results = run_sparql_query(knowledge_graph, sparql_query)\n",
    "        for result in sparql_results:\n",
    "            all_results.append([\n",
    "                getattr(result.o1, \"toPython\", lambda: result.o1)(),  # Use getattr with default lambda\n",
    "                getattr(result.o2, \"toPython\", lambda: result.o2)(),  # Use getattr with default lambda\n",
    "                int(result.links)\n",
    "            ])\n",
    "    # Return the pandas DataFrame from the list of results\n",
    "    results = pd.DataFrame(all_results,\n",
    "                        columns=[\"conceptual_item_1\", \"conceptual_item_2\", \"use_number\"])\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_table_with_links(knowledge_graph: rdflib.Graph,\n",
    "                         sparql_queries: set = direct_history_preface,\n",
    "                         history_table_option: bool = True\n",
    "                         ) -> pd.DataFrame:\n",
    "    \"\"\"Retrieves a table of textual units, conceptual items, and their usage numbers.\n",
    "\n",
    "    Executes a set of SPARQL queries on the knowledge graph to extract links between\n",
    "    textual units and conceptual items, along with their usage numbers.\n",
    "\n",
    "    Args:\n",
    "        knowledge_graph: The rdflib.Graph object representing the knowledge graph.\n",
    "        sparql_queries: A list of SPARQL query names to execute. Defaults to sparql_queries_withouth_hierarchical_imports.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with columns \"textual_unit\", \"conceptual_item\", and \"use_number\".\n",
    "    \"\"\"\n",
    "    if history_table_option:\n",
    "        results = get_table_history_queries(knowledge_graph, sparql_queries)\n",
    "    else:\n",
    "        results = get_table_hebbian_queries(knowledge_graph, sparql_queries)\n",
    "\n",
    "    # Order results\n",
    "    results = results.sort_values(by=[\"use_number\"], ascending=[False])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_-dS-krn_N6"
   },
   "source": [
    "## HISTORICAL ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_direct_history(kg: rdflib.Graph,\n",
    "#                        sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\")):\n",
    "#     pass\n",
    "    # get_direct_history_definitions()\n",
    "    # get_direct_history_postulates()\n",
    "    # get_direct_history_common_notions()\n",
    "\n",
    "    # return direct_history\n",
    "\n",
    "def get_preface_history(kg: rdflib.Graph,\n",
    "                        direct_history_preface: set = direct_history_preface,\n",
    "                        hierarhical_history_preface: set = hierarhical_history_preface,\n",
    "                        indirect_mereological_history_medium_importance_preface: set = indirect_mereological_history_medium_importance_preface,\n",
    "                        sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\")):\n",
    "    # preface history: definition, postulates, common axioms\n",
    "    direct_history_preface_df = get_table_with_links(kg, direct_history_preface)\n",
    "\n",
    "    # get indirect hierarchical history\n",
    "    hierachical_history_preface_df = get_table_with_links(kg, hierarhical_history_preface)\n",
    "\n",
    "    # get indirect mereological history\n",
    "    indirect_mereological_history_preface_df = get_table_with_links(kg, indirect_mereological_history_medium_importance_preface)\n",
    "\n",
    "    return [direct_history_preface_df, hierachical_history_preface_df, indirect_mereological_history_preface_df]\n",
    "\n",
    "def historical_activation_computation(historical_activation_potential: dict,\n",
    "                                      specific_history: pd.DataFrame,\n",
    "                                      weight: float):\n",
    "    total = specific_history[\"use_number\"].sum()\n",
    "    for index in specific_history.index:\n",
    "        conceptual_item = specific_history[\"conceptual_item\"][index]\n",
    "        historical_activation_potential[conceptual_item] += ( (weight * specific_history[\"use_number\"][index]) / total )\n",
    "    return historical_activation_potential\n",
    "\n",
    "def get_historical_activation_potential(history: list,\n",
    "                                        weight_direct: float = 6/9,\n",
    "                                        weight_hierarchical: float = 1/9,\n",
    "                                        weight_mereological: float = 2/9):\n",
    "    # initialize the dictionary to compute the historical activation potential\n",
    "    historical_activation_potential = {\n",
    "        conceptual_item: 0\n",
    "            for specific_history in history\n",
    "            for conceptual_item in specific_history[\"conceptual_item\"]\n",
    "    }\n",
    "    # add the use numbers from the three histories\n",
    "    for specific_history in history:\n",
    "        activation = historical_activation_computation(\n",
    "            historical_activation_potential, specific_history, weight_direct)\n",
    "\n",
    "    # concert the dictionary to a dataframe\n",
    "    historical_activation_potential = pd.DataFrame(\n",
    "            list(historical_activation_potential.items()),\n",
    "            columns=['conceptual_item', 'activation_potential']\n",
    "        )\n",
    "\n",
    "    return historical_activation_potential\n",
    "\n",
    "\n",
    "\n",
    "def get_history(kg: rdflib.Graph,\n",
    "                sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\"),\n",
    "                up_to_proposition: int = 0,\n",
    "                base: dict = {}):\n",
    "    if base:\n",
    "        pass\n",
    "        # find highest proposition P in base\n",
    "        # if P < up_to_proposition,\n",
    "        # find the history of the propositions\n",
    "        # between P (excluded) and up_to_proposition (included)\n",
    "\n",
    "        # if P = up_to_proposition,\n",
    "        # find the history of the propositions\n",
    "        # between P (excluded) and up_to_proposition (included)\n",
    "\n",
    "        # if P > up_to_proposition,\n",
    "        # remove the history for propositions > up_to_proposition\n",
    "        # return history\n",
    "    else:\n",
    "        # get direct history of definitions, postulates, and common notions\n",
    "\n",
    "        # get direct history up to the given proposition number\n",
    "        if up_to_proposition == 0:\n",
    "            history = get_preface_history(kg)\n",
    "            return history\n",
    "        elif up_to_proposition > 1:\n",
    "            pass\n",
    "            # return history\n",
    "        else:\n",
    "            return ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEEHJWc6d2J_"
   },
   "source": [
    "## HEBBIAN ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_hebbian_table(kg: rdflib.Graph,\n",
    "#                       sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\"),\n",
    "#                       up_to_proposition: int = 0):\n",
    "#     # get_hebbian_connections\n",
    "#     hebbian_connections = get_table_with_links(kg, hebbian_connections_preface, history_table_option = False)\n",
    "\n",
    "#     return hebbian_connections\n",
    "\n",
    "\n",
    "def compute_hebbian_activation(hebbian_table: pd.DataFrame):\n",
    "    # initialize dictionary for hebbian activation potentials\n",
    "    hebbian_potential = {}\n",
    "    # sum of all hebbian connections\n",
    "    total_use_number = hebbian_table['use_number'].sum()\n",
    "    # add hebbian activation potentials to the dictionary\n",
    "    for row in hebbian_table.itertuples():\n",
    "        concepts = tuple(sorted([row.conceptual_item_1, row.conceptual_item_2]))\n",
    "        hebbian_activation = row.use_number / total_use_number\n",
    "        hebbian_potential[concepts] = hebbian_activation\n",
    "\n",
    "    hebbian_df = pd.DataFrame(list(hebbian_potential.items()),\n",
    "                              columns=[\"conceptual_item\", \"activation_potential\"])\n",
    "    return hebbian_df\n",
    "\n",
    "def get_hebbian_activation(kg: rdflib.Graph,\n",
    "                           sparql_queries_folder: str = os.path.join(\"input\", \"sparql_queries\"),\n",
    "                           sparql_queries: set = hebbian_connections_preface,\n",
    "                           up_to_proposition: int = 0,\n",
    "                           base: dict = {}):\n",
    "    if base:\n",
    "        pass\n",
    "    else:\n",
    "        if up_to_proposition == 0:\n",
    "            hebbian_table = get_table_with_links(kg, sparql_queries, history_table_option = False)\n",
    "            hebbian_potential = compute_hebbian_activation(hebbian_table)\n",
    "            return hebbian_potential\n",
    "        elif up_to_proposition > 1:\n",
    "            pass\n",
    "        else:\n",
    "            return ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S50yRm-iGqb9"
   },
   "source": [
    "# UNIFIED ACTIVATION POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(historical_activation_potential: pd.DataFrame,\n",
    "                hebbian_activation_potential: pd.DataFrame):\n",
    "    context = set(historical_activation_potential['conceptual_item'])\n",
    "    for pair in hebbian_activation_potential['conceptual_item']:\n",
    "        context.update(pair)\n",
    "    return context\n",
    "\n",
    "def calculate_activation(conceptual_item,\n",
    "                         historical_activation_potential_dict: dict,\n",
    "                         hebbian_activation_potential_dict: dict,\n",
    "                         context_length: int,\n",
    "                         history_weight: float = 2/3,\n",
    "                         hebbian_weight: float = 1/3):\n",
    "    # history part\n",
    "    weigthed_historical_activation = history_weight * historical_activation_potential_dict.get(conceptual_item, 0)\n",
    "    # hebbian part\n",
    "    weighted_hebbian_activation = 0\n",
    "    for item, value in hebbian_activation_potential_dict.items():\n",
    "        if conceptual_item in item:\n",
    "            weighted_hebbian_activation += hebbian_weight * (hebbian_activation_potential_dict[item] / context_length)\n",
    "    # total activation potential\n",
    "    return weigthed_historical_activation + weighted_hebbian_activation\n",
    "\n",
    "def get_activation_potential(historical_activation_potential: pd.DataFrame,\n",
    "                             hebbian_activation_potential: pd.DataFrame):\n",
    "    # get context\n",
    "    context = get_context(historical_activation_potential, hebbian_activation_potential)\n",
    "    # create dictionaries\n",
    "    historical_activation_potential_dict = dict(zip(historical_activation_potential['conceptual_item'],\n",
    "                                                    historical_activation_potential['activation_potential']))\n",
    "    hebbian_activation_potential_dict = dict(zip(hebbian_activation_potential['conceptual_item'],\n",
    "                                                 hebbian_activation_potential['activation_potential']))\n",
    "\n",
    "    # initialize dictionary of unified activation potentials\n",
    "    activations = {}\n",
    "\n",
    "    # calculate the unified activation potential for each conceptual item\n",
    "    context_length = len(hebbian_activation_potential)\n",
    "    for conceptual_item in context:\n",
    "        activations[conceptual_item] = calculate_activation(\n",
    "                conceptual_item,\n",
    "                historical_activation_potential_dict,\n",
    "                hebbian_activation_potential_dict,\n",
    "                context_length\n",
    "            )\n",
    "    activations_df = pd.DataFrame(list(activations.items()),\n",
    "                                  columns=[\"conceptual_item\", \"activation_potential\"])\n",
    "    return activations_df.sort_values(by=[\"activation_potential\"], ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO5LCVlWeA4d"
   },
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_name: str):\n",
    "    # access turtle file\n",
    "    kg = access_graph(file_name)\n",
    "\n",
    "    ###########\n",
    "    # preface\n",
    "        # history\n",
    "    history = get_history(kg)\n",
    "    historical_activation_potential = get_historical_activation_potential(history)\n",
    "        # hebbian\n",
    "    hebbian_activation_potential = get_hebbian_activation(kg)\n",
    "    print(hebbian_activation_potential)\n",
    "        # activation potential\n",
    "    activation_potential = get_activation_potential(\n",
    "            historical_activation_potential,\n",
    "            hebbian_activation_potential\n",
    "        )\n",
    "\n",
    "    return activation_potential\n",
    "\n",
    "\n",
    "activation_potential = main(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_potential[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_potential.to_csv(\"output/activation_potential.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
