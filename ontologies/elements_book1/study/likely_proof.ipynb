{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eaf3154",
   "metadata": {},
   "source": [
    "# Likely activation potential: SPEC\n",
    "\n",
    "This notebook will implement the *likely co-occurrence* component and likely activation potential from `main.tex`, using the same ontology input and operational choices as `typical_proof.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897920ba",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Compute likely activation potential for resources used in each proof `N`, using:\n",
    "- context `C` (same as in `typical_proof.ipynb`),\n",
    "- a *salient set* `S` defined by one of two variants (selectable by a flag),\n",
    "- likely co-occurrence `Φ_{L_c}(r, C, S)` and likely activation `Φ_L(r, C, S)`.\n",
    "\n",
    "Output one CSV per analysis; filenames must encode key parameters and include a timestamp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581008ce",
   "metadata": {},
   "source": [
    "## Inputs / Parameters\n",
    "- `START_PROPOSITION`, `END_PROPOSITION`: proof range (same semantics as `typical_proof.ipynb`).\n",
    "- `EPSILON`: weight for `Φ_L = ε * Φ_h + (1 - ε) * Φ_{L_c}` (parallel to `DELTA` in typical).\n",
    "- `HISTORY_WEIGHTS`: 3-tuple `(α, β, γ)` for direct/hierarchical/mereological histories (same validation rules).\n",
    "- `TYPE_SELECTION`: boolean, if `True` use relation/operation types in proposition/proof queries; if `False` use direct concepts.\n",
    "- `S_VARIANT`: enum flag in `{\"statement_only\", \"statement_plus_related_chunks\"}` selecting the salient set definition.\n",
    "- `EXCLUDED_CONCEPT_IRIS`, `EXCLUDED_CONCEPT_IRI_SUBSTRINGS`: same filtering behavior as in `typical_proof.ipynb`.\n",
    "- Input TTL: use the same selection logic as `typical_proof.ipynb` (latest TTL in `ontologies/`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bf0e1",
   "metadata": {},
   "source": [
    "## Context `C` (same as `typical_proof.ipynb`)\n",
    "For each proof `N`:\n",
    "- `C` includes resources from definitions, postulates, common notions, and propositions up to `N` (included), plus proofs up to `N-1` (included).\n",
    "- Use the same query families as `typical_proof.ipynb` for direct / hierarchical / mereological histories and Hebbian co-occurrence.\n",
    "- Apply the same exclusion filters after each query materializes.\n",
    "- Build `hebb_C` using the same operational definition of “together” as `typical_proof.ipynb`:\n",
    "  resources co-occur if they are used in the same definition, postulate, common notion, proposition, or proof (via `refers_to` / `contains_concept`).\n",
    "- Preserve the same ordered-pair caveat used in `typical_proof.ipynb` (queries return `(o1, o2)` pairs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631c13e",
   "metadata": {},
   "source": [
    "## Salient set `S` (two variants)\n",
    "Let `last_proposition` be proposition `N` (the statement immediately preceding proof `N`).\n",
    "\n",
    "**Variant 1: `S_VARIANT = \"statement_only\"`**\n",
    "- `S` = resources in the *statement* of `last_proposition`.\n",
    "- Implement via a dedicated SPARQL query (to be written) that extracts resources from the statement, with `TYPE_SELECTION` applied.\n",
    "\n",
    "**Variant 2: `S_VARIANT = \"statement_plus_related_chunks\"`**\n",
    "- Let `S0` be the resources in the statement of `last_proposition` (as above).\n",
    "- Let `R` be the set of resources that occur in any chunk (definition, postulate, common notion, proposition, or proof)\n",
    "  that shares at least one resource with `S0`.\n",
    "- Then `S = S0 ∪ R`.\n",
    "- Implement via a dedicated SPARQL query (to be written) that\n",
    "  (a) identifies chunks sharing at least one resource with `S0`, and\n",
    "  (b) returns all resources from those chunks, with `TYPE_SELECTION` applied.\n",
    "\n",
    "For each variant, apply the same exclusion filters as in `typical_proof.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b669c",
   "metadata": {},
   "source": [
    "## Likely co-occurrence (`Φ_{L_c}`)\n",
    "- Build `hebb_C` exactly as in the typical analysis, using the same “together” definition.\n",
    "- Compute `deg_C^S(r) = sum_{r' in S, r' != r} hebb_C(r, r')`.\n",
    "- Define:\n",
    "  - `Φ_{L_c}(r, C, S) = deg_C^S(r) / sum_u deg_C^S(u)` if denominator ≠ 0, else 0.\n",
    "- This is computed only for resources *used in proof `N`* (same as typical).\n",
    "\n",
    "## Likely activation potential (`Φ_L`)\n",
    "- Compute historical component `Φ_h(r, C)` using the same direct/hierarchical/mereological histories and weights as typical.\n",
    "- Combine with likely co-occurrence:\n",
    "  `Φ_L(r, C, S) = ε * Φ_h(r, C) + (1 - ε) * Φ_{L_c}(r, C, S)`\n",
    "  where `ε = EPSILON` in `[0, 1]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949e215",
   "metadata": {},
   "source": [
    "## Four analyses (S variant × TYPE_SELECTION)\n",
    "Run all four combinations:\n",
    "1. `S_VARIANT=statement_only`, `TYPE_SELECTION=False`\n",
    "2. `S_VARIANT=statement_only`, `TYPE_SELECTION=True`\n",
    "3. `S_VARIANT=statement_plus_related_chunks`, `TYPE_SELECTION=False`\n",
    "4. `S_VARIANT=statement_plus_related_chunks`, `TYPE_SELECTION=True`\n",
    "\n",
    "Each run should iterate proofs `N` in `[START_PROPOSITION, END_PROPOSITION]`, compute\n",
    "`Φ_h`, `Φ_{L_c}`, `Φ_L`, and the set of new resources (same definition as in typical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c8bea",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "For each analysis, write one CSV with rows per `(proof_n, resource)` that include at least:\n",
    "- `proof_n`\n",
    "- `resource_used_in_proof`\n",
    "- `phi_h`\n",
    "- `phi_lc` (likely co-occurrence)\n",
    "- `phi_l` (likely activation)\n",
    "- `is_new_resource` (or a separate list/count of new resources, mirroring typical output)\n",
    "\n",
    "**Filename requirements**\n",
    "- Must include: `S_VARIANT`, `TYPE_SELECTION`, proof range, and a timestamp.\n",
    "- Example pattern: `likely_{s_variant}_type_{type_flag}_p{start}-{end}_{YYYYmmdd_HHMMSS}.csv`\n",
    "\n",
    "The output directory should mirror `typical_proof.ipynb` (e.g., `output/`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcf032",
   "metadata": {},
   "source": [
    "## Query placeholders (to be authored)\n",
    "Add new SPARQL queries in `modules/queries.py` for:\n",
    "- `salient_statement_resources(last_proposition, TYPE_SELECTION)`\n",
    "- `salient_statement_plus_related_chunks(last_proposition, TYPE_SELECTION)`\n",
    "\n",
    "The spec requires that both queries:\n",
    "- return resources as `?o` with optional counts,\n",
    "- respect `TYPE_SELECTION`, and\n",
    "- are filtered by `EXCLUDED_CONCEPT_IRIS` and `EXCLUDED_CONCEPT_IRI_SUBSTRINGS`\n",
    "  immediately after each query result is materialized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28231579",
   "metadata": {},
   "source": [
    "## Validation / Edge cases\n",
    "- If `S` is empty, then all `deg_C^S` are 0 and `Φ_{L_c}` must be 0.\n",
    "- If `hebb_C` is empty, `Φ_{L_c}` must be 0.\n",
    "- Ensure `EPSILON ∈ [0,1]` and `HISTORY_WEIGHTS` sum to 1.\n",
    "- For `N=1`, context contains definitions, postulates, common notions, and proposition 1; there are no prior proofs.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
