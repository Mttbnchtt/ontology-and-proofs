{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eaf3154",
   "metadata": {},
   "source": [
    "# Likely activation potential: SPEC\n",
    "\n",
    "This notebook will implement the *likely co-occurrence* component and likely activation potential from `main.tex`, using the same ontology input and operational choices as `typical_proof.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897920ba",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Compute likely activation potential for resources used in each proof `N`, using:\n",
    "- context `C` (same as in `typical_proof.ipynb`),\n",
    "- a *salient set* `S` defined by one of two variants (selectable by a flag),\n",
    "- likely co-occurrence `Φ_{L_c}(r, C, S)` and likely activation `Φ_L(r, C, S)`.\n",
    "\n",
    "Output one CSV per analysis; filenames must encode key parameters and include a timestamp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581008ce",
   "metadata": {},
   "source": [
    "## Inputs / Parameters\n",
    "- `START_PROPOSITION`, `END_PROPOSITION`: proof range (same semantics as `typical_proof.ipynb`).\n",
    "- `EPSILON`: weight for `Φ_L = ε * Φ_h + (1 - ε) * Φ_{L_c}` (parallel to `DELTA` in typical).\n",
    "- `HISTORY_WEIGHTS`: 3-tuple `(α, β, γ)` for direct/hierarchical/mereological histories (same validation rules).\n",
    "- `TYPE_SELECTION`: boolean, if `True` use relation/operation types in proposition/proof queries; if `False` use direct concepts.\n",
    "- `S_VARIANT`: enum flag in `{\"statement_only\", \"statement_plus_related_chunks\"}` selecting the salient set definition.\n",
    "- `EXCLUDED_CONCEPT_IRIS`, `EXCLUDED_CONCEPT_IRI_SUBSTRINGS`: same filtering behavior as in `typical_proof.ipynb`.\n",
    "- Input TTL: use the same selection logic as `typical_proof.ipynb` (latest TTL in `ontologies/`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bf0e1",
   "metadata": {},
   "source": [
    "## Context `C` (same as `typical_proof.ipynb`)\n",
    "For each proof `N`:\n",
    "- `C` includes resources from definitions, postulates, common notions, and propositions up to `N` (included), plus proofs up to `N-1` (included).\n",
    "- Use the same query families as `typical_proof.ipynb` for direct / hierarchical / mereological histories and Hebbian co-occurrence.\n",
    "- Apply the same exclusion filters after each query materializes.\n",
    "- Build `hebb_C` using the same operational definition of “together” as `typical_proof.ipynb`:\n",
    "  resources co-occur if they are used in the same definition, postulate, common notion, proposition, or proof (via `refers_to` / `contains_concept`).\n",
    "- Preserve the same ordered-pair caveat used in `typical_proof.ipynb` (queries return `(o1, o2)` pairs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631c13e",
   "metadata": {},
   "source": [
    "## Salient set `S` (two variants)\n",
    "Let `last_proposition` be proposition `N` (the statement immediately preceding proof `N`).\n",
    "\n",
    "**Variant 1: `S_VARIANT = \"statement_only\"`**\n",
    "- `S` = resources in the *statement* of `last_proposition`.\n",
    "- Implement via a dedicated SPARQL query (to be written) that extracts resources from the statement, with `TYPE_SELECTION` applied.\n",
    "\n",
    "**Variant 2: `S_VARIANT = \"statement_plus_related_chunks\"`**\n",
    "- Let `S0` be the resources in the statement of `last_proposition` (as above).\n",
    "- Let `R` be the set of resources that occur in any chunk (definition, postulate, common notion, proposition, or proof)\n",
    "  that shares at least one resource with `S0`.\n",
    "- Then `S = S0 ∪ R`.\n",
    "- Implement via a dedicated SPARQL query (to be written) that\n",
    "  (a) identifies chunks sharing at least one resource with `S0`, and\n",
    "  (b) returns all resources from those chunks, with `TYPE_SELECTION` applied.\n",
    "\n",
    "For each variant, apply the same exclusion filters as in `typical_proof.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b669c",
   "metadata": {},
   "source": [
    "## Likely co-occurrence (`Φ_{L_c}`)\n",
    "- Build `hebb_C` exactly as in the typical analysis, using the same “together” definition.\n",
    "- Compute `deg_C^S(r) = sum_{r' in S, r' != r} hebb_C(r, r')`.\n",
    "- Define:\n",
    "  - `Φ_{L_c}(r, C, S) = deg_C^S(r) / sum_u deg_C^S(u)` if denominator ≠ 0, else 0.\n",
    "- This is computed only for resources *used in proof `N`* (same as typical).\n",
    "\n",
    "## Likely activation potential (`Φ_L`)\n",
    "- Compute historical component `Φ_h(r, C)` using the same direct/hierarchical/mereological histories and weights as typical.\n",
    "- Combine with likely co-occurrence:\n",
    "  `Φ_L(r, C, S) = ε * Φ_h(r, C) + (1 - ε) * Φ_{L_c}(r, C, S)`\n",
    "  where `ε = EPSILON` in `[0, 1]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949e215",
   "metadata": {},
   "source": [
    "## Four analyses (S variant × TYPE_SELECTION)\n",
    "Run all four combinations:\n",
    "1. `S_VARIANT=statement_only`, `TYPE_SELECTION=False`\n",
    "2. `S_VARIANT=statement_only`, `TYPE_SELECTION=True`\n",
    "3. `S_VARIANT=statement_plus_related_chunks`, `TYPE_SELECTION=False`\n",
    "4. `S_VARIANT=statement_plus_related_chunks`, `TYPE_SELECTION=True`\n",
    "\n",
    "Each run should iterate proofs `N` in `[START_PROPOSITION, END_PROPOSITION]`, compute\n",
    "`Φ_h`, `Φ_{L_c}`, `Φ_L`, and the set of new resources (same definition as in typical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c8bea",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "For each analysis, write one CSV with rows per `(proof_n, resource)` that include at least:\n",
    "- `proof_n`\n",
    "- `resource_used_in_proof`\n",
    "- `phi_h`\n",
    "- `phi_lc` (likely co-occurrence)\n",
    "- `phi_l` (likely activation)\n",
    "- `is_new_resource` (or a separate list/count of new resources, mirroring typical output)\n",
    "\n",
    "**Filename requirements**\n",
    "- Must include: `S_VARIANT`, `TYPE_SELECTION`, proof range, and a timestamp.\n",
    "- Example pattern: `likely_{s_variant}_type_{type_flag}_p{start}-{end}_{YYYYmmdd_HHMMSS}.csv`\n",
    "\n",
    "The output directory should mirror `typical_proof.ipynb` (e.g., `output/`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcf032",
   "metadata": {},
   "source": [
    "## SPARQL queries\n",
    "\n",
    "\n",
    "CASE 1: salient_statement_resources\n",
    "For salient_statement_resources(last_proposition, type_selection=False) use the following SPARQL queries:\n",
    "- queries.direct_template_propositions_proofs(last_proposition)\n",
    "- queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "- queries.mereological_template_propositions_proofs(last_proposition). [components of statement resources are statement resources]\n",
    "\n",
    "For salient_statement_resources(last_proposition, type_selection=True) use the following SPARQL queries:\n",
    "- queries.direct_template_last_item_types(last_proposition)\n",
    "- queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "- queries.mereological_template_propositions_proofs(last_proposition). [components of statement resources are statement resources]\n",
    "\n",
    "These SPARQL queries provide resources and counts. Then the notebook can use these results to proceed with the required calculations.\n",
    "\n",
    "CASE 2: salient_statement_plus_related_chunks\n",
    "For salient_statement_plus_related_chunks(last_proposition, type_selection=False) use the following SPARQL queries:\n",
    "(a) queries.direct_template_propositions_proofs(last_proposition)\n",
    "(b) queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "(c) queries.mereological_template_propositions_proofs(last_proposition) [components of statement resources are statement resources]\n",
    "(d) queries.find_salient_resources_in_definitions_postulates_common_notions(resource_iris)\n",
    "(e) queries.direct_definitions()\n",
    "(f) queries.direct_postulates()\n",
    "(g) queries.direct_common_notions()\n",
    "(h) queries.hierarchical_definitions()\n",
    "(i) queries.hierarchical_postulates()\n",
    "(j) queries.hierarchical_common_notions()\n",
    "(k) queries.mereological_definitions()\n",
    "(l) queries.mereological_postulates()\n",
    "(m) queries.mereological_common_notions().\n",
    "\n",
    "For salient_statement_plus_related_chunks(last_proposition, type_selection=True) use the following SPARQL queries:\n",
    "(a) queries.direct_template_last_item_types(last_proposition)\n",
    "(b) queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "(c) queries.mereological_template_propositions_proofs(last_proposition) [components of statement resources are statement resources]\n",
    "(d) queries.find_salient_resources_in_definitions_postulates_common_notions(resource_iris)\n",
    "(e) queries.direct_definitions()\n",
    "(f) queries.direct_postulates()\n",
    "(g) queries.direct_common_notions()\n",
    "(h) queries.hierarchical_definitions()\n",
    "(i) queries.hierarchical_postulates()\n",
    "(j) queries.hierarchical_common_notions()\n",
    "(k) queries.mereological_definitions()\n",
    "(l) queries.mereological_postulates()\n",
    "(m) queries.mereological_common_notions().\n",
    "\n",
    "TO DO: add new queries to modules/queries.py that are like queries (e)-(m) but parametrized via `VALUES {{ {iri_of_salient_resources} }}`.\n",
    "\n",
    "The queries (a), (b), and (c) find both the resources that are salient in the last proposition and the counts. \n",
    "Reuse the counts for later calculations.sue the resources to create the string resource_iris (adding angular brakets as needed) in queries.find_salient_resources_in_definitions_postulates_common_notions (query (d) in the list above) to find the definitions, postulates, and common notions to be considered.\n",
    "Use queries (e) thru (m) to find the additional counts needed for later calculations.\n",
    "\n",
    "The spec requires that both queries:\n",
    "- return resources as `?o` with optional counts,\n",
    "- respect `TYPE_SELECTION`, and\n",
    "- are filtered by `EXCLUDED_CONCEPT_IRIS` and `EXCLUDED_CONCEPT_IRI_SUBSTRINGS`\n",
    "  immediately after each query result is materialized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28231579",
   "metadata": {},
   "source": [
    "## Validation / Edge cases\n",
    "- If `S` is empty, then all `deg_C^S` are 0 and `Φ_{L_c}` must be 0.\n",
    "- If `hebb_C` is empty, `Φ_{L_c}` must be 0.\n",
    "- Ensure `EPSILON ∈ [0,1]` and `HISTORY_WEIGHTS` sum to 1.\n",
    "- For `N=1`, context contains definitions, postulates, common notions, and proposition 1; there are no prior proofs.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
