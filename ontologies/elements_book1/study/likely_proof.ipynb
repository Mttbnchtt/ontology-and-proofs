{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eaf3154",
   "metadata": {},
   "source": [
    "# Likely activation potential: SPEC\n",
    "\n",
    "This notebook will implement the *likely co-occurrence* component and likely activation potential from `main.tex`, using the same ontology input and operational choices as `typical_proof.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897920ba",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Compute likely activation potential for resources used in each proof `N`, using:\n",
    "- context `C` (same as in `typical_proof.ipynb`),\n",
    "- a *salient set* `S` defined by one of two variants (selectable by a flag),\n",
    "- likely co-occurrence `Φ_{L_c}(r, C, S)` and likely activation `Φ_L(r, C, S)`.\n",
    "\n",
    "Output one CSV per analysis; filenames must encode key parameters and include a timestamp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581008ce",
   "metadata": {},
   "source": [
    "## Inputs / Parameters\n",
    "- `START_PROPOSITION`, `END_PROPOSITION`: proof range (same semantics as `typical_proof.ipynb`).\n",
    "- `EPSILON`: weight for `Φ_L = ε * Φ_h + (1 - ε) * Φ_{L_c}` (parallel to `DELTA` in typical).\n",
    "- `HISTORY_WEIGHTS`: 3-tuple `(α, β, γ)` for direct/hierarchical/mereological histories (same validation rules).\n",
    "- `TYPE_SELECTION`: boolean, if `True` use relation/operation types in proposition/proof queries; if `False` use direct concepts.\n",
    "- `S_VARIANT`: enum flag in `{\"statement_only\", \"statement_plus_related_chunks\"}` selecting the salient set definition.\n",
    "- `EXCLUDED_CONCEPT_IRIS`, `EXCLUDED_CONCEPT_IRI_SUBSTRINGS`: same filtering behavior as in `typical_proof.ipynb`.\n",
    "- Input TTL: use the same selection logic as `typical_proof.ipynb` (latest TTL in `ontologies/`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bf0e1",
   "metadata": {},
   "source": [
    "## Context `C` (same as `typical_proof.ipynb`)\n",
    "For each proof `N`:\n",
    "- `C` includes resources from definitions, postulates, common notions, and propositions up to `N` (included), plus proofs up to `N-1` (included).\n",
    "- Use the same query families as `typical_proof.ipynb` for direct / hierarchical / mereological histories and Hebbian co-occurrence.\n",
    "- Apply the same exclusion filters after each query materializes.\n",
    "- Build `hebb_C` using the same operational definition of “together” as `typical_proof.ipynb`:\n",
    "  resources co-occur if they are used in the same definition, postulate, common notion, proposition, or proof (via `refers_to` / `contains_concept`).\n",
    "- Preserve the same ordered-pair caveat used in `typical_proof.ipynb` (queries return `(o1, o2)` pairs).\n",
    "- Counting convention: keep duplicates (multiset semantics). When combining query outputs, do not deduplicate by resource; retain multiplicities/counts and aggregate by summing counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631c13e",
   "metadata": {},
   "source": [
    "## Salient set `S` (two variants)\n",
    "Let `last_proposition` be proposition `N` (the statement immediately preceding proof `N`).\n",
    "Assumption: proof `N` is always immediately after proposition `N`.\n",
    "\n",
    "**Variant 1: `S_VARIANT = \"statement_only\"`**\n",
    "- `S` = resources in the *statement* of `last_proposition`.\n",
    "- Implement via a dedicated SPARQL query that extracts resources from the statement, with `TYPE_SELECTION` applied.\n",
    "\n",
    "**Variant 2: `S_VARIANT = \"statement_plus_related_chunks\"`**\n",
    "- Let `S0` be the resources in the statement of `last_proposition` (as above).\n",
    "- Let `R` be the set of resources that occur in any chunk (definition, postulate, common notion, proposition, or proof) before the proof under discussion.\n",
    "  that shares at least one resource with `S0`.\n",
    "- Then `S = S0 ∪ R`.\n",
    "- Implement via a dedicated SPARQL query that\n",
    "  (a) identifies chunks sharing at least one resource with `S0`, and\n",
    "  (b) returns all resources from those chunks, with `TYPE_SELECTION` applied.\n",
    "\n",
    "For each variant, apply the same exclusion filters as in `typical_proof.ipynb`.\n",
    "\n",
    "The multiset ‘keep duplicates’ rule applies to context/history/hebb aggregations; S is always deduplicated (set semantics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b669c",
   "metadata": {},
   "source": [
    "## Likely co-occurrence (`Φ_{L_c}`)\n",
    "- Build `hebb_C` exactly as in the typical analysis, using the same “together” definition.\n",
    "- Compute `deg_C^S(r) = sum_{r' in S, r' != r} hebb_C(r, r')`.\n",
    "- Define:\n",
    "  - `Φ_{L_c}(r, C, S) = deg_C^S(r) / sum_u deg_C^S(u)` if denominator ≠ 0, else 0.\n",
    "  - Denominator scope: `sum_u deg_C^S(u)` is over all resources in context `C`.\n",
    "- This is computed only for resources *used in proof `N`* (same as typical).\n",
    "\n",
    "## Likely activation potential (`Φ_L`)\n",
    "- Compute historical component `Φ_h(r, C)` using the same direct/hierarchical/mereological histories and weights as typical.\n",
    "- Combine with likely co-occurrence:\n",
    "  `Φ_L(r, C, S) = ε * Φ_h(r, C) + (1 - ε) * Φ_{L_c}(r, C, S)`\n",
    "  where `ε = EPSILON` in `[0, 1]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949e215",
   "metadata": {},
   "source": [
    "## Four analyses (S variant × TYPE_SELECTION)\n",
    "Run all four combinations:\n",
    "1. `S_VARIANT=statement_only`, `TYPE_SELECTION=False`\n",
    "2. `S_VARIANT=statement_only`, `TYPE_SELECTION=True`\n",
    "3. `S_VARIANT=statement_plus_related_chunks`, `TYPE_SELECTION=False`\n",
    "4. `S_VARIANT=statement_plus_related_chunks`, `TYPE_SELECTION=True`\n",
    "\n",
    "Each run should iterate proofs `N` in `[START_PROPOSITION, END_PROPOSITION]`, compute\n",
    "`Φ_h`, `Φ_{L_c}`, `Φ_L`, and the set of new resources (same definition as in typical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c8bea",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "For each analysis, write one CSV with rows per `(proof, resource)` and mirror the structure of `typical_proof.ipynb`:\n",
    "- `proof`\n",
    "- `resource_used_in_proof`\n",
    "- `number_of_resources_used_in_proof`\n",
    "- `phi_h`\n",
    "- `phi_lc` (likely co-occurrence)\n",
    "- `phi_l` (likely activation)\n",
    "- `new_resources`\n",
    "- `number_of_new_resources`\n",
    "- `new_resources` and `number_of_new_resources` are per-proof data and are repeated across all rows of the same proof (as in `typical_proof.ipynb`).\n",
    "\n",
    "**Filename requirements**\n",
    "- Must include: `S_VARIANT`, `TYPE_SELECTION`, proof range, and a timestamp.\n",
    "- Example pattern: `likely_{s_variant}_type_{type_flag}_p{start}-{end}_{YYYYmmdd_HHMMSS}.csv`\n",
    "\n",
    "The output directory should mirror `typical_proof.ipynb` (e.g., `output/`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcf032",
   "metadata": {},
   "source": [
    "## SPARQL queries\n",
    "\n",
    "\n",
    "CASE 1: salient_statement_resources\n",
    "For salient_statement_resources(last_proposition, type_selection=False) use the following SPARQL queries:\n",
    "- queries.direct_template_propositions_proofs(last_proposition)\n",
    "- queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "- queries.mereological_template_propositions_proofs(last_proposition). [components of statement resources are statement resources]\n",
    "\n",
    "For salient_statement_resources(last_proposition, type_selection=True) use the following SPARQL queries:\n",
    "- queries.direct_template_last_item_types(last_proposition)\n",
    "- queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "- queries.mereological_template_propositions_proofs(last_proposition). [components of statement resources are statement resources]\n",
    "\n",
    "Clarification: for `TYPE_SELECTION=True`, this mixed setup is intentional and correct: direct statement resources are taken at type level, while hierarchical and mereological expansions remain concept-level as listed.\n",
    "\n",
    "These SPARQL queries provide resources and counts. Then the notebook can use these results to proceed with the required calculations.\n",
    "\n",
    "CASE 2: salient_statement_plus_related_chunks\n",
    "For salient_statement_plus_related_chunks(last_proposition, type_selection=False) use the following SPARQL queries:\n",
    "(a) queries.direct_template_propositions_proofs(last_proposition)\n",
    "(b) queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "(c) queries.mereological_template_propositions_proofs(last_proposition) [components of statement resources are statement resources]\n",
    "(d) queries.find_salient_definitions_postulates_common_notions(resource_iris) [outputs: IRIs of definitions, postulates, common notions]\n",
    "(e) queries.find_salient_propositions_proofs(resource_iris, proposition_number) [outputs: IRIs of propositions, and proofs]\n",
    "(f) queries.direct_definitions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(g) queries.direct_postulates_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(h) queries.direct_common_notions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(i) queries.hierarchical_definitions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(j) queries.hierarchical_postulates_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(k) queries.hierarchical_common_notions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(l) queries.mereological_definitions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(m) queries.mereological_postulates_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(n) queries.mereological_common_notions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(o) queries.direct_template_propositions_proofs_selected_values(iri_of_salient_resources). [use IRIs from queries (e)]\n",
    "Contract for (d): it musts return the IRIs to be used as `iri_of_salient_resources` VALUES input for queries (f) through (n). \n",
    "Contract for (e): it musts return the IRIs to be used as `iri_of_salient_resources` VALUES input for query (o).\n",
    "\n",
    "For salient_statement_plus_related_chunks(last_proposition, type_selection=True) use the following SPARQL queries:\n",
    "(a) queries.direct_template_last_item_types(last_proposition)\n",
    "(b) queries.hierarchical_template_propositions_proofs(last_proposition) [super-concepts of statement resources are statement resources]\n",
    "(c) queries.mereological_template_propositions_proofs(last_proposition) [components of statement resources are statement resources]\n",
    "(d) queries.find_salient_definitions_postulates_common_notions(resource_iris)  [outputs: IRIs of definitions, postulates, common notions]\n",
    "(e) queries.find_salient_propositions_proofs(resource_iris, proposition_number) [outputs: IRIs of propositions, and proofs]\n",
    "(f) queries.direct_definitions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(g) queries.direct_postulates_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(h) queries.direct_common_notions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(i) queries.hierarchical_definitions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(j) queries.hierarchical_postulates_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(k) queries.hierarchical_common_notions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(l) queries.mereological_definitions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(m) queries.mereological_postulates_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(n) queries.mereological_common_notions_selected_values(iri_of_salient_resources) [use IRIs from queries (d)]\n",
    "(o) queries.direct_template_propositions_proofs_selected_values(iri_of_salient_resources). [use IRIs from queries (e)]\n",
    "Contract for (d): it musts return the IRIs to be used as `iri_of_salient_resources` VALUES input for queries (f) through (n). \n",
    "Contract for (e): it musts return the IRIs to be used as `iri_of_salient_resources` VALUES input for query (o).\n",
    "\n",
    "The queries (a), (b), and (c) find both the resources that are salient in the last proposition and the counts. \n",
    "Reuse the counts for later calculations. Use the resources to create the string resource_iris (adding angular brakets as needed) in queries.find_salient_definitions_postulates_common_notions (query (d) in the list above) and queries.find_salient_propositions_proofs (query (e) in the list above) to find the definitions, postulates, common notions, propositions, and proofs to be considered.\n",
    "Use queries (f) thru (o) to find the additional counts needed for later calculations.\n",
    "\n",
    "The spec requires that all queries:\n",
    "- return resources as `?o` with optional counts (except for query find_salient_definitions_postulates_common_notions() and find_salient_propositions_proofs(), which have no COUNT() and the code should be careful about this),\n",
    "- respect `TYPE_SELECTION`, and\n",
    "- are filtered by `EXCLUDED_CONCEPT_IRIS` and `EXCLUDED_CONCEPT_IRI_SUBSTRINGS`\n",
    "  immediately after each query result is materialized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28231579",
   "metadata": {},
   "source": [
    "## Validation / Edge cases\n",
    "- If `S` is empty, then all `deg_C^S` are 0 and `Φ_{L_c}` must be 0.\n",
    "- If `hebb_C` is empty, `Φ_{L_c}` must be 0.\n",
    "- Ensure `EPSILON ∈ [0,1]` and `HISTORY_WEIGHTS` sum to 1.\n",
    "- For `N=1`, context contains definitions, postulates, common notions, and proposition 1; there are no prior proofs.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
