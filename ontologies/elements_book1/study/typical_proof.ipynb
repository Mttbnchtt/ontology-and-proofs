{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5890d888",
   "metadata": {},
   "source": [
    "# Typical activation potential: analysis of each proof N against context\n",
    "\n",
    "This notebook implements the *typical activation potential* from `main.tex`.\n",
    "\n",
    "Notation (from `main.tex`):\n",
    "- Phi_T(r, C) is the typical activation potential for resource r in context C.\n",
    "- Phi_h(r, C) is the historical component of activation potential.\n",
    "- Phi_Tc(r, C) is the typical co-occurrence component (Phi_{T_c}).\n",
    "- delta (DELTA in code) is the weight in Phi_T = delta * Phi_h + (1 - delta) * Phi_Tc, with delta in [0, 1].\n",
    "\n",
    "Assumptions (matching the existing SPARQL queries):\n",
    "\n",
    "Assumption: The SPARQL queries used in this notebook were verified to implement the paper's definitions of\n",
    "context C and \"together\" (per definition/postulate/common notion or proposition/proof).\n",
    "If query scopes are changed, results may no longer match the formulas in `main.tex`.\n",
    "- Context C for proof n are the resources in definitions, postulates, common notions, propositions up to n (included), and proofs up to n-1 (included)\n",
    "- \"Together\" for co-occurrence means resources that co-occur within the same definition, postulate, common notion, proposition, or proof.\n",
    "- Phi_h is computed from history queries; Phi_Tc is computed from Hebbian pair degrees (co-occurrence links); Phi_T uses the weighted sum above.\n",
    "- Empty denominators yield 0 for the corresponding potential.\n",
    "- TYPE_SELECTION toggles type-based co-occurrence for propositions/proofs (relation/operation types) when true.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6925534",
   "metadata": {},
   "source": [
    "# SPEC\n",
    "\n",
    "GOALS: \n",
    "(1) Apply the description of typical activation potential provided in main.tex to compute the activation potential of resources used in proof N against the context of resources used in definitions, postulates, common notions, propositions up to N (included), and proofs up to N-1 (included; if N=1, then there is no proof to include in the context). \n",
    "(2) Note when proof N uses _directly_ a resource that has not appeared anywhere in the context (i.e. in the definitions, postulates, common notions, propositions up to N included, and proofs up to N-1 included). For proof N, use direct_template_propositions_proofs if TYPE_SELECTION = False and direct_template_last_item_types if TYPE_SELECTION = True. Define new_resources as the subset of the direct‑usage set from the ‘HOW TO FIND RESOURCES IN PROOF N’ step that does not occur in the context.\n",
    "\n",
    "PREPARATION: review \n",
    "    - main.tex (for the definition of typical activation potential), \n",
    "    - analyses.ipynb (for strategies to compare proofs with their context of previous material), and \n",
    "    - typical.ipynb (for an algorithm implementing typical activation potential)\n",
    "    - ./modules/queries.py (for SPARQL queries used to work with ontological resources)\n",
    "\n",
    "NOTES:\n",
    "    - cache results of SPARQL queries for faster re-runs (QueryRunner)\n",
    "\n",
    "INPUTS: PROOF_N, DELTA, HISTORY_WEIGHTS (exactly 3 weights required), TYPE_SELECTION\n",
    "\n",
    "HOW TO CREATE THE CONTEXT OF PROOF N:\n",
    "- directly used resources: use queries.direct_definitions(), queries.direct_postulates(), queries.direct_common_notions(), and queries.direct_template_propositions_proofs() for propositions up to N (included) and proofs up to N-1 (included) [for propositions and proofs, one need to state the IRIs as VALUES in the SPARQL queries]\n",
    "- hierarchically used resources: use queries.hierarchical_definitions(), queries.hierarchical_postulates(), queries.hierarchical_common_notions(), and hierarchical_template_propositions_proofs for propositions up to N (included) and proofs up to N-1 (included) [for propositions and proofs, one need to state the IRIs as VALUES in the SPARQL queries]\n",
    "- mereologically used resources: use queries.mereological_definitions(), queries.mereological_postulates(), queries.mereological_common_notions, queries.mereological_template_propositions_proofs() for propositions up to N (included) and proofs up to N-1 (included) [for propositions and proofs, one need to state the IRIs as VALUES in the SPARQL queries]\n",
    "- hebbian co-occurrence: use queries.hebb_definitions(), queries.hebb_postulates(), queries.hebb_common_notions(), and queries.hebb_template_propositions_proofs() for propositions up to N (included) and proofs up to N-1 (included) [for propositions and proofs, one need to state the IRIs as VALUES in the SPARQL queries].\n",
    "\n",
    "EDGE CASE:\n",
    "- N = 1: the context includes only definitions, postulates, common notions, and proposition 1.\n",
    "\n",
    "HOW TO FIND RESOURCES IN PROOF N:\n",
    "- if TYPE_SELECTION = False: use queries.direct_template_propositions_proofs() for proof N (the list of values for the query should contain only the IRI of proof N)\n",
    "- if TYPE_SELECTION = True: use queries.direct_template_last_item_types() for proof N (the list of values for the query should contain only the IRI of proof N)\n",
    "\n",
    "OUTPUT: \n",
    "    - csv with columns \"proof\", \"resource_used_in_proof\", \"number_of_resources_used_in_proof\", \"phi_h\", \"phi_tc\", \"phi_t\", \"new_resources\", \"number_of_new_resources\"\n",
    "    - include only resources used in proof N (for each N) in the column \"resource_used_in_proof\"\n",
    "    - output path: put the csv file in the \"./output\" folder\n",
    "    - output naming convention: typical_weights-<history_weights>_type-<true_or_false>_<timestamp>.csv\n",
    "    - \"number_of_resources_used_in_proof\" is a column of scalars that counts how many resources a proof contains (set-size, not multiplicity; it is a per-proof piece of data but we keep it in this csv)\n",
    "    - \"new_resources\" contains a list of resources that are new in proof N (never used before)\n",
    "    - \"new_resources\", \"number_of_new_resources\" are per-proof data; however I want to include them in a single csv; therefore, it is ok to repeat these data on several rows for the same proof\n",
    "\n",
    "Note on reuse: `rdf_utils.sparql_to_concat_df` could replace the local aggregation helpers because it is query-agnostic,\n",
    "but `calculate_activation_potential.hebb` returns pair-level potentials (this notebook needs per-resource degrees),\n",
    "and `calculate_activation_potential.history` scopes propositions/proofs up to N-1 and does not support type selection,\n",
    "so they are not drop-in fits for this spec.\n",
    "\n",
    "Note on TYPE_SELECTION: in analyses.ipynb, type_selection only switches proof-level direct resources to relation/operation types,\n",
    "while history and co-occurrence stay concept-based. In typical_proof.ipynb, TYPE_SELECTION switches both proof resources\n",
    "and Hebbian co-occurrence queries to type-based variants; history context remains concept-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a00b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from modules import rdf_utils, file_utils\n",
    "from modules.query_runner import QueryRunner\n",
    "    \n",
    "OUTPUT_DIR = Path('output')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# functions to create context for proof N\n",
    "from modules.typical_context import build_context_for_proof\n",
    "# functions to gather resources from proof N\n",
    "from modules.typical_proof_resources import resources_in_proof\n",
    "# functions to calculate the historical activation potential Phi_h\n",
    "from modules.typical_activation import compute_phi_h\n",
    "# functions to calculate the co-occurrence activation potential Phi_Tc\n",
    "from modules.typical_activation import compute_phi_tc\n",
    "# functions to calculate the total activation potential Phi_T\n",
    "from modules.typical_activation import compute_phi_t\n",
    "# functions to find resources in proof N that are not in the context\n",
    "from modules.typical_activation import compute_new_resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec7053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: Load latest ontology TTL and reuse a cached QueryRunner\n",
    "INPUT_TTL = file_utils.latest_file(folder=Path('ontologies'), filename_fragment='ontology_', extension='ttl')\n",
    "graph = rdf_utils.load_graph(INPUT_TTL)\n",
    "runner = QueryRunner(graph)\n",
    "\n",
    "#####################################################################\n",
    "# STEP 1: define parameters\n",
    "DELTA = 0.5  # delta in Phi_T = delta * Phi_h + (1 - delta) * Phi_Tc\n",
    "HISTORY_WEIGHTS = (6 / 9, 1 / 9, 2 / 9)  # Phi_h weights: direct, hierarchical, mereological\n",
    "\n",
    "# NOTE: Although the SPEC lists PROOF_N as an input, \n",
    "# this notebook runs a batch analysis by iterating over a range of proofs. \n",
    "# We therefore use START_PROPOSITION/END_PROPOSITION and \n",
    "# treat each iteration as the current PROOF_N\n",
    "START_PROPOSITION = 1\n",
    "END_PROPOSITION = 48\n",
    "\n",
    "\n",
    "def validate_params() -> None:\n",
    "    if not (0.0 <= DELTA <= 1.0):\n",
    "        raise ValueError(f\"DELTA must be in [0, 1], got {DELTA}.\")\n",
    "    if len(HISTORY_WEIGHTS) != 3:\n",
    "        raise ValueError(\n",
    "            f\"HISTORY_WEIGHTS must have length 3, got {len(HISTORY_WEIGHTS)}.\"\n",
    "        )\n",
    "    if any((w < 0.0 or w > 1.0) for w in HISTORY_WEIGHTS):\n",
    "        raise ValueError(\"All HISTORY_WEIGHTS must be in [0, 1].\")\n",
    "    total = sum(HISTORY_WEIGHTS)\n",
    "    if abs(total - 1.0) > 1e-9:\n",
    "        raise ValueError(f\"HISTORY_WEIGHTS must sum to 1, got {total}.\")\n",
    "    \n",
    "validate_params()\n",
    "\n",
    "#####################################################################\n",
    "def run_analysis(type_selection: bool) -> tuple[pd.DataFrame, Path]:\n",
    "    \"\"\"Run the full analysis for a given type selection, save CSV, and return results.\"\"\"\n",
    "    results_rows: list[dict[str, object]] = []\n",
    "    for proof_n in range(START_PROPOSITION, END_PROPOSITION + 1):\n",
    "        context_resources, family_dfs, hebb_df = build_context_for_proof(\n",
    "            proof_n,\n",
    "            runner=runner,\n",
    "            type_selection=type_selection,\n",
    "        )\n",
    "        proof_resources = resources_in_proof(\n",
    "            proof_n,\n",
    "            runner=runner,\n",
    "            type_selection=type_selection,\n",
    "        )\n",
    "        proof_resources_sorted = sorted(proof_resources)\n",
    "\n",
    "        phi_h_df = compute_phi_h(proof_resources_sorted, family_dfs, HISTORY_WEIGHTS)\n",
    "        phi_tc_df = compute_phi_tc(proof_resources_sorted, hebb_df)\n",
    "        phi_t_df = compute_phi_t(proof_resources_sorted, phi_h_df, phi_tc_df, DELTA)\n",
    "\n",
    "        new_resources = compute_new_resources(proof_resources_sorted, context_resources)\n",
    "        proof_count = len(proof_resources_sorted)\n",
    "        new_count = len(new_resources)\n",
    "\n",
    "        phi_h_map = dict(zip(phi_h_df[\"resource_used_in_proof\"], phi_h_df[\"phi_h\"]))\n",
    "        phi_tc_map = dict(zip(phi_tc_df[\"resource_used_in_proof\"], phi_tc_df[\"phi_tc\"]))\n",
    "        phi_t_map = dict(zip(phi_t_df[\"resource_used_in_proof\"], phi_t_df[\"phi_t\"]))\n",
    "\n",
    "        for resource in proof_resources_sorted:\n",
    "            results_rows.append({\n",
    "                \"proof\": proof_n,\n",
    "                \"resource_used_in_proof\": resource,\n",
    "                \"number_of_resources_used_in_proof\": proof_count,\n",
    "                \"phi_h\": float(phi_h_map.get(resource, 0.0)),\n",
    "                \"phi_tc\": float(phi_tc_map.get(resource, 0.0)),\n",
    "                \"phi_t\": float(phi_t_map.get(resource, 0.0)),\n",
    "                \"new_resources\": new_resources,\n",
    "                \"number_of_new_resources\": new_count,\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        results_rows,\n",
    "        columns=[\n",
    "            \"proof\",\n",
    "            \"resource_used_in_proof\",\n",
    "            \"number_of_resources_used_in_proof\",\n",
    "            \"phi_h\",\n",
    "            \"phi_tc\",\n",
    "            \"phi_t\",\n",
    "            \"new_resources\",\n",
    "            \"number_of_new_resources\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    history_weights_label = \"-\".join(f\"{w:.4f}\" for w in HISTORY_WEIGHTS)\n",
    "    timestamp = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    type_label = str(type_selection).lower()\n",
    "    output_path = OUTPUT_DIR / (\n",
    "        f\"typical_weights-{history_weights_label}_type-{type_label}_{timestamp}.csv\"\n",
    "    )\n",
    "\n",
    "    print(f\"Total proofs processed: {END_PROPOSITION - START_PROPOSITION + 1}\")\n",
    "    print(f\"Total rows: {len(results_df)}\")\n",
    "\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "    return results_df, output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adff958",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_false, output_path_false = run_analysis(False)\n",
    "print(\"TYPE_SELECTION=False\")\n",
    "results_df_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_true, output_path_true = run_analysis(True)\n",
    "print(\"TYPE_SELECTION=True\")\n",
    "results_df_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8f7a0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
