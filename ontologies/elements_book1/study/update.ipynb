{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4881d754",
   "metadata": {},
   "source": [
    "# ADD ELEMENTS TO THE ONTOLOGY OF EUCLID'S BOOK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "NOTEBOOK_DIR = pathlib.Path.cwd()\n",
    "if '_NB_SYS_PATH_ADJUSTED' not in globals():\n",
    "    sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "    _NB_SYS_PATH_ADJUSTED = True\n",
    "\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "\n",
    "from modules import legacy_utils\n",
    "from modules import rdf_utils\n",
    "\n",
    "URIREF = rdflib.URIRef\n",
    "RDF_TYPE = rdflib.RDF.type\n",
    "RDFS_LABEL = rdflib.RDFS.label\n",
    "SKOS_PREFLABEL = rdflib.SKOS.prefLabel\n",
    "CONCEPT_CLASS = URIREF(\"https://www.foom.com/core#concept\")\n",
    "NAMESPACE = \"<https://www.foom.com/core>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import rdf_utils\n",
    "\n",
    "def load_graph(input_ttl: pathlib.Path) -> rdflib.Graph:\n",
    "    graph = rdf_utils.read_graph(str(input_ttl))\n",
    "    return graph\n",
    "\n",
    "#  read input ontology file\n",
    "INPUT_TTL = NOTEBOOK_DIR.parent / \"ontologies\" / \"ontology_euclid_book1.ttl\"\n",
    "g = load_graph(INPUT_TTL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb187b",
   "metadata": {},
   "source": [
    "## CONCEPTUAL COMPONENTS OF POSTULATES AND COMMON NOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add contains_concepts relations to postulates and common notions\n",
    "from modules import legacy_utils\n",
    "from modules.import rdf_utils\n",
    "\n",
    "INPUT_FILE = NOTEBOOK_DIR / \"input\" / \"addenda_contains_concept.csv\"\n",
    "OUTPUT_FOLDER = NOTEBOOK_DIR / \"ontologies\"\n",
    "\n",
    "def add_concept(\n",
    "    g: rdflib.Graph,\n",
    "    concept_string: str\n",
    "):\n",
    "    concept_label = concept_string.replace(\"_\", \" \")\n",
    "    concept_iri = legacy_utils.create_iri(f\"Concept: {concept_string}\")\n",
    "    g.add((URIREF(concept_iri), RDF_TYPE, CONCEPT_CLASS))\n",
    "    g.add((URIREF(concept_iri), RDFS_LABEL, rdflib.Literal(f\"Concept: {concept_label}\")))\n",
    "    g.add((URIREF(concept_iri), SKOS_PREFLABEL, rdflib.Literal(concept_label)))\n",
    "    return g, concept_iri\n",
    "\n",
    "def contains_concepts(\n",
    "    g: rdflib.Graph,\n",
    "    input_file: pathlib.Path = INPUT_FILE\n",
    "):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(input_file)\n",
    "    concepts = set()\n",
    "    for _, row in df.iterrows():\n",
    "        subject_iri = URIREF(row['subject'])\n",
    "        objects = {concept.strip() for concept in row['objects'].split(',')}\n",
    "        for object_string in objects:\n",
    "            object_iri = legacy_utils.create_iri(f\"Concept: {object_string}\")\n",
    "            concepts.add(object_string)\n",
    "            # add triples to the graph\n",
    "            g.add((\n",
    "                URIREF(subject_iri),\n",
    "                URIREF(\"https://www.foom.com/core#contains_concept\"),\n",
    "                URIREF(object_iri)))\n",
    "            g.add((\n",
    "                URIREF(object_iri),\n",
    "                URIREF(\"https://www.foom.com/core#is_concept_in\"),\n",
    "                URIREF(subject_iri)))\n",
    "    return g, concepts\n",
    "\n",
    "\n",
    "def write_csv(\n",
    "        iris_df: pd.DataFrame, \n",
    "        *, \n",
    "        filename: str = \"concepts.csv\", \n",
    "        output_dir: pathlib.Path = OUTPUT_FOLDER\n",
    "    ) -> pathlib.Path:\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = output_dir / filename\n",
    "    iris_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved iris to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def add_concepts_and_contains_concept(\n",
    "    g: rdflib.Graph,\n",
    "    input_file: pathlib.Path = INPUT_FILE\n",
    "):\n",
    "    g, concepts = contains_concepts(g, input_file)\n",
    "    print(f\"Added {len(concepts)} new concepts to the graph.\")\n",
    "    iris = set()\n",
    "    for concept_string in concepts:\n",
    "        g, concept_iri = add_concept(g, concept_string)\n",
    "        iris.add(concept_iri)\n",
    "    iris_df = pd.DataFrame({\"iri\": sorted(iris)})\n",
    "    write_csv(iris_df)\n",
    "    return g\n",
    "\n",
    "# g = add_concepts_and_contains_concept(g, INPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d197f0",
   "metadata": {},
   "source": [
    "## CONCPETUAL COMPONENTS OF ALL CONCEPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46113f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import rdf_utils\n",
    "INPUT_CSV = NOTEBOOK_DIR / \"input\" / \"conceptual_components.csv\"\n",
    "OUTPUT_FOLDER = NOTEBOOK_DIR / \"ontologies\"\n",
    "\n",
    "CONTAINS_CONCEPT = URIREF(\"https://www.foom.com/core#contains_concept\")\n",
    "IS_CONCEPT_IN = URIREF(\"https://www.foom.com/core#is_concept_in\")\n",
    "\n",
    "def add_conceptual_components(\n",
    "    g: rdflib.Graph,\n",
    "    input_csv: pathlib.Path = INPUT_CSV\n",
    "):\n",
    "    # read csv file with concepts and their conceptual components\n",
    "    df = pd.read_csv(input_csv).fillna(\"\")\n",
    "\n",
    "    # iterate over rows and \n",
    "    # add triples <s, oai:contains_concept, o> and\n",
    "    # <o, oai:is_concept_in, s>\n",
    "    # to the graph\n",
    "    for _, row in df.iterrows():\n",
    "        subject_iri = URIREF(row['concept_iri'])\n",
    "        if component_values := row['component']:\n",
    "            components = {component.strip() for component in component_values.split(';')}\n",
    "            for component_string in components:\n",
    "                component_iri = URIREF(component_string)\n",
    "                # add triples to the graph\n",
    "                g.add((\n",
    "                    subject_iri,\n",
    "                    CONTAINS_CONCEPT,\n",
    "                    component_iri))\n",
    "                g.add((\n",
    "                    component_iri,\n",
    "                    IS_CONCEPT_IN,\n",
    "                    subject_iri))\n",
    "    \n",
    "    print(\"Length of graph after adding conceptual components:\", len(g))\n",
    "    save_graph_with_timestamp(\n",
    "        g, \n",
    "        output_dir=OUTPUT_FOLDER,)\n",
    "    return g\n",
    "\n",
    "g = add_conceptual_components(g, INPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d1e6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def save_graph_with_timestamp(graph):\n",
    "    \"\"\"Serialize graph to a timestamped Turtle file in the study output folder.\"\"\"\n",
    "    output_dir = Path(\"/Users/matteobianchetti/Documents/Chen.Chen.1/Filosofia/Logica/Mathematics/Math_subjects/Computer_science/Git_repositories/GitHub/ontology-and-proofs/ontologies/elements_book1/study/output\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_path = output_dir / f\"ontology_{timestamp}.ttl\"\n",
    "    graph.serialize(destination=output_path, format=\"turtle\")\n",
    "    return output_path\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
