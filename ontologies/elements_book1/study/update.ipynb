{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4881d754",
   "metadata": {},
   "source": [
    "# ADD ELEMENTS TO THE ONTOLOGY OF EUCLID'S BOOK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "NOTEBOOK_DIR = pathlib.Path.cwd()\n",
    "if '_NB_SYS_PATH_ADJUSTED' not in globals():\n",
    "    sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "    _NB_SYS_PATH_ADJUSTED = True\n",
    "\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "\n",
    "from modules import legacy_utils\n",
    "from modules import rdf_utils\n",
    "\n",
    "URIREF = rdflib.URIRef\n",
    "RDF_TYPE = rdflib.RDF.type\n",
    "RDFS_LABEL = rdflib.RDFS.label\n",
    "SKOS_PREFLABEL = rdflib.SKOS.prefLabel\n",
    "CONCEPT_CLASS = URIREF(\"https://www.foom.com/core#concept\")\n",
    "CONTAINS_CONCEPT = URIREF(\"https://www.foom.com/core#contains_concept\")\n",
    "IS_CONCEPT_IN = URIREF(\"https://www.foom.com/core#is_concept_in\")\n",
    "NAMESPACE = \"<https://www.foom.com/core>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb187b",
   "metadata": {},
   "source": [
    "## CONCEPTUAL COMPONENTS OF POSTULATES AND COMMON NOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add contains_concepts relations to postulates and common notions\n",
    "from modules import legacy_utils\n",
    "from modules import file_utils\n",
    "from modules import rdf_utils\n",
    "\n",
    "INPUT_FILE = NOTEBOOK_DIR / \"input\" / \"addenda_contains_concept.csv\"\n",
    "OUTPUT_FOLDER = NOTEBOOK_DIR / \"ontologies\"\n",
    "\n",
    "\n",
    "def add_concept(\n",
    "    g: rdflib.Graph,\n",
    "    concept_string: str\n",
    "):\n",
    "    concept_label = concept_string.replace(\"_\", \" \")\n",
    "    concept_iri = legacy_utils.create_iri(f\"Concept: {concept_string}\")\n",
    "    g.add((concept_iri, RDF_TYPE, CONCEPT_CLASS))\n",
    "    g.add((concept_iri, RDFS_LABEL, rdflib.Literal(f\"Concept: {concept_label}\")))\n",
    "    g.add((concept_iri, SKOS_PREFLABEL, rdflib.Literal(concept_label)))\n",
    "    return g, concept_iri\n",
    "\n",
    "\n",
    "def contains_concepts(\n",
    "    g: rdflib.Graph,\n",
    "    df: pd.DataFrame = INPUT_FILE\n",
    "):\n",
    "    concepts = set()\n",
    "    for _, row in df.iterrows():\n",
    "        subject_iri = URIREF(row['subject'])\n",
    "        objects = {concept.strip() for concept in row['objects'].split(',')}\n",
    "        for object_string in objects:\n",
    "            object_iri = legacy_utils.create_iri(f\"Concept: {object_string}\")\n",
    "            concepts.add(object_string)\n",
    "            # add triples to the graph\n",
    "            g.add((\n",
    "                subject_iri,\n",
    "                CONTAINS_CONCEPT,\n",
    "                object_iri))\n",
    "            g.add((\n",
    "                object_iri,\n",
    "                IS_CONCEPT_IN,\n",
    "                subject_iri))\n",
    "    \n",
    "    print(f\"Added {len(concepts)} new concepts to the graph.\")\n",
    "    return g, concepts\n",
    "\n",
    "\n",
    "def add_concepts(\n",
    "    g: rdflib.Graph, \n",
    "    concepts: set[str]\n",
    "):\n",
    "    iris = set()\n",
    "    for concept_string in concepts:\n",
    "        g, concept_iri = add_concept(g, concept_string)\n",
    "        iris.add(concept_iri)\n",
    "    iris_df = pd.DataFrame({\"iri\": sorted(iris)})\n",
    "    return g, iris_df\n",
    "    \n",
    "def add_concepts_and_contains_concept_from_postulates_and_common_notions(\n",
    "    g: rdflib.Graph,\n",
    "    input_file: pathlib.Path = INPUT_FILE\n",
    "):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # add contains_concept relations\n",
    "    g, concepts = contains_concepts(g, df)\n",
    "\n",
    "    # add concept under the Concept class\n",
    "    g, iris_df = add_concepts(g, concepts, df)\n",
    "\n",
    "    # output graph to ttl file\n",
    "    rdf_utils.save_graph_with_timestamp(\n",
    "        g, \n",
    "        output_subdir=OUTPUT_FOLDER)\n",
    "\n",
    "    # output csv\n",
    "    file_utils.write_csv(\n",
    "        iris_df, \n",
    "        filename=\"new_concepts_from_postulates_common_notions.csv\", \n",
    "        output_dir=\"output\")\n",
    "    return g\n",
    "\n",
    "#  read input ontology file\n",
    "INPUT_TTL = file_utils.latest_ontology_file()\n",
    "g = rdf_utils.load_graph(INPUT_TTL)\n",
    "\n",
    "# add concepts and contains_concept relations\n",
    "g = add_concepts_and_contains_concept_from_postulates_and_common_notions(g, INPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d197f0",
   "metadata": {},
   "source": [
    "## CONCEPTUAL COMPONENTS OF ALL CONCEPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46113f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import rdf_utils\n",
    "INPUT_CSV = NOTEBOOK_DIR / \"input\" / \"conceptual_components.csv\"\n",
    "OUTPUT_FOLDER = NOTEBOOK_DIR / \"ontologies\"\n",
    "\n",
    "def add_conceptual_components(\n",
    "    g: rdflib.Graph,\n",
    "    input_csv: pathlib.Path = INPUT_CSV\n",
    "):\n",
    "    # read csv file with concepts and their conceptual components\n",
    "    df = pd.read_csv(input_csv).fillna(\"\")\n",
    "\n",
    "    # iterate over rows and \n",
    "    # add triples <s, oai:contains_concept, o> and\n",
    "    # <o, oai:is_concept_in, s>\n",
    "    # to the graph\n",
    "    for _, row in df.iterrows():\n",
    "        subject_iri = URIREF(row['concept_iri'])\n",
    "        if component_values := row['component']:\n",
    "            components = {component.strip() for component in component_values.split(';')}\n",
    "            for component_string in components:\n",
    "                component_iri = URIREF(component_string)\n",
    "                # add triples to the graph\n",
    "                g.add((\n",
    "                    subject_iri,\n",
    "                    CONTAINS_CONCEPT,\n",
    "                    component_iri))\n",
    "                g.add((\n",
    "                    component_iri,\n",
    "                    IS_CONCEPT_IN,\n",
    "                    subject_iri))\n",
    "    \n",
    "    print(\"Length of graph after adding conceptual components:\", len(g))\n",
    "    rdf_utils.save_graph_with_timestamp(\n",
    "        g, \n",
    "        output_subdir=OUTPUT_FOLDER,)\n",
    "    return g\n",
    "\n",
    "#  read input ontology file\n",
    "INPUT_TTL = file_utils.latest_ontology_file()\n",
    "g = rdf_utils.load_graph(INPUT_TTL)\n",
    "\n",
    "# add conceptual components to concepts\n",
    "g = add_conceptual_components(g, INPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d1e6d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
